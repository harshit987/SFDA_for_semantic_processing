{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "approach1_task1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24d122dc41834ffb99b1ba0d9e371b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_395ceb5be89a45ac9ba200a23026dd67",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4567a062b5d646d58d127e4e80d032db",
              "IPY_MODEL_7547338a56eb4913b9184b9a2820caf3"
            ]
          }
        },
        "395ceb5be89a45ac9ba200a23026dd67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4567a062b5d646d58d127e4e80d032db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2f47e87377204b39937117eda124e396",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 563,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 563,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_803e82d4652c4b9d9e6d1d67496c70ff"
          }
        },
        "7547338a56eb4913b9184b9a2820caf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_499a3b73b62a4e6ab8eee8cb847f5064",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 563/563 [00:26&lt;00:00, 21.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bfdcf6bd1f8e41b4b047f22fb662f27d"
          }
        },
        "2f47e87377204b39937117eda124e396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "803e82d4652c4b9d9e6d1d67496c70ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "499a3b73b62a4e6ab8eee8cb847f5064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bfdcf6bd1f8e41b4b047f22fb662f27d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11ab425d34ce4a69a31a1103853addac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3137f39c6a9c4f91a95d581420007282",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1530d67637b4477486852b8172fa23b4",
              "IPY_MODEL_08ba07bbcfc14b5cb4952e23cf597f3d"
            ]
          }
        },
        "3137f39c6a9c4f91a95d581420007282": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1530d67637b4477486852b8172fa23b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f7a74f5375b4ffab54c4ceae80ad92e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898822,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898822,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f3ff9f7d9f145bd83b7a3a1c768fe38"
          }
        },
        "08ba07bbcfc14b5cb4952e23cf597f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6399fe66b332442f91e8a32795db243e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 5.02MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9eb0801148e4b079e81761b2399d8c5"
          }
        },
        "4f7a74f5375b4ffab54c4ceae80ad92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f3ff9f7d9f145bd83b7a3a1c768fe38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6399fe66b332442f91e8a32795db243e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9eb0801148e4b079e81761b2399d8c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9150c3e5c95543d7b669f8f43b722bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eb812316cb904c4fa3afdd1147a98f9e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db5612ac772d42d1bad1d9819604b11a",
              "IPY_MODEL_8c6620abccdc4196a1a687c7fade93d4"
            ]
          }
        },
        "eb812316cb904c4fa3afdd1147a98f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db5612ac772d42d1bad1d9819604b11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_438393bce4f44d039bdf99f790f15a08",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d46e9cdaff9427b9473c2d7fafd46da"
          }
        },
        "8c6620abccdc4196a1a687c7fade93d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45a229cd243b44378e6d6cec41b67e29",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 953kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f3a92ebfb674b728dace8c65d2e4d8e"
          }
        },
        "438393bce4f44d039bdf99f790f15a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d46e9cdaff9427b9473c2d7fafd46da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45a229cd243b44378e6d6cec41b67e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f3a92ebfb674b728dace8c65d2e4d8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e721f1cd62ae4733a10b2211a3b9cdad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fdb5d5af48e7455f9d491957a34fb631",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7c8773208f1041d6800ec8c2bc29b4a8",
              "IPY_MODEL_3c9d7b3d9d6c40069d5cc87136a5befb"
            ]
          }
        },
        "fdb5d5af48e7455f9d491957a34fb631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c8773208f1041d6800ec8c2bc29b4a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6f3c14b305da431d843dbc7bfccc6437",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c43785a67a774cdba8100a27f9a73da4"
          }
        },
        "3c9d7b3d9d6c40069d5cc87136a5befb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea592daaf0c64ea28a65e599842d0836",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 116B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47e6ab7ce4714e199f77a0446b75194a"
          }
        },
        "6f3c14b305da431d843dbc7bfccc6437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c43785a67a774cdba8100a27f9a73da4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea592daaf0c64ea28a65e599842d0836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47e6ab7ce4714e199f77a0446b75194a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "268e1d92ba354e7f8ae316080f6f782c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e87f586eb2d649c7a61709b599e0d844",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7be911c77f4a46f5b88850d9c721a939",
              "IPY_MODEL_ae5e6d9cb4604a0ea1acb31d790812da"
            ]
          }
        },
        "e87f586eb2d649c7a61709b599e0d844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7be911c77f4a46f5b88850d9c721a939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_367df4ee61ed46bc9b1b36e09e538ee6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 818,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 818,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b30cfcd8fa0b4d92bef0bf9a4794a212"
          }
        },
        "ae5e6d9cb4604a0ea1acb31d790812da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8359beed45404e4e896340ba3dcc21d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 818/818 [00:00&lt;00:00, 6.01kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a591fb8b65e43e19a96afb0eca3e736"
          }
        },
        "367df4ee61ed46bc9b1b36e09e538ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b30cfcd8fa0b4d92bef0bf9a4794a212": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8359beed45404e4e896340ba3dcc21d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a591fb8b65e43e19a96afb0eca3e736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23994b84bf9e44008aaa7a837b18ed92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d40c3feec19446bf805faa9b460dfbd2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_77b0cf0246b24f96930d580b17f4ba6f",
              "IPY_MODEL_36eea7654e9b481fb964c9985e30eab5"
            ]
          }
        },
        "d40c3feec19446bf805faa9b460dfbd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77b0cf0246b24f96930d580b17f4ba6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_575110d2a655490e849c600f1ea6927c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 71,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 71,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04672cddd7634e2cb4bb4296f90ad6f5"
          }
        },
        "36eea7654e9b481fb964c9985e30eab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8233357fab4e41f88d152714bdc0774c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 71.0/71.0 [00:00&lt;00:00, 609B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2530275a389f42e0a1c1f79eeedc58cd"
          }
        },
        "575110d2a655490e849c600f1ea6927c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04672cddd7634e2cb4bb4296f90ad6f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8233357fab4e41f88d152714bdc0774c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2530275a389f42e0a1c1f79eeedc58cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "268ba618e40c416897f1c4b45a1b029d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9c3c83c6f686431089d2e3ee36fcdd1e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2e3d116a8b84884b518c335c11ddcb5",
              "IPY_MODEL_b58a4b6abbf74d45a5d418f53235dbd9"
            ]
          }
        },
        "9c3c83c6f686431089d2e3ee36fcdd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2e3d116a8b84884b518c335c11ddcb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_764b10360b394a3ebc109e5624004730",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501013463,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501013463,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_476c502581474954b0858b7b256d74c9"
          }
        },
        "b58a4b6abbf74d45a5d418f53235dbd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce823db654ad4ee78a0d46b50c77b4bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:24&lt;00:00, 20.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e1ff9bca8114ffeadcc684b1224285c"
          }
        },
        "764b10360b394a3ebc109e5624004730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "476c502581474954b0858b7b256d74c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce823db654ad4ee78a0d46b50c77b4bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e1ff9bca8114ffeadcc684b1224285c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gi8dnlk4E3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b96c149d-6f9a-462a-864a-bdb17944d42b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI2JxyBvGto1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d9e679-0c0e-485f-84ab-e3f65a461415"
      },
      "source": [
        "## using code from https://github.com/tim-learn/SHOT\n",
        "## & https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=DEfSbAA4QHas\n",
        "## & https://github.com/youngryan1993/SFDA-Domain-Adaptation-without-Source-Data\n",
        "# !pip3 install -r 'drive/My Drive/source-free-domain-adaptation/baselines/negation/requirements.txt'\n",
        "!pip3 install torchviz\n",
        "!pip3 install transformers==3.02"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 29.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 32.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 19.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.7.0+cu101)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (3.7.4.3)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3522 sha256=5beab20799c14da23f0053c96ced1eb57f128e00c1455fac1ca0f654dcd73f31\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n",
            "Collecting transformers==3.02\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/f4/9f93f06dd2c57c7cd7aa515ffbf9fcfd8a084b92285732289f4a5696dd91/transformers-3.2.0-py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 14.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 53.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 55.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (20.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.02) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.02) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.02) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.02) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.02) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.02) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.02) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.02) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=e2010a165fa5e59da9648463e00e52a1db3dc0bfa6f744d9814f8f167f8e92c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.8.1rc2 transformers-3.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7azDws-7Qus"
      },
      "source": [
        "from tabulate import tabulate\n",
        "import logging\n",
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from transformers.data.processors.utils import InputExample, InputFeatures\n",
        "from transformers.data.processors.glue import glue_convert_examples_to_features\n",
        "from transformers.data.processors.utils import DataProcessor\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "\n",
        "labels = [\"-1\", \"1\"]\n",
        "max_length = 128\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akyyfQDE7cg3"
      },
      "source": [
        "import argparse\n",
        "import os, sys\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import random, pdb, math, copy\n",
        "from tqdm import tqdm\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZta4KFeR0Ne"
      },
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn.functional as F\n",
        "def seed_everything(seed=3000):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    import os\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "seed_everything()\n",
        "train_min_step = 1000\n",
        "train_lr=0.0001\n",
        "train_weight_decay = 0.0005\n",
        "train_momentum = 0.9\n",
        "train_update_freq = 50\n",
        "# for step, batch in enumerate(train_dataloader):\n",
        "#   print(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8bj6Zm57VP8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355,
          "referenced_widgets": [
            "24d122dc41834ffb99b1ba0d9e371b90",
            "395ceb5be89a45ac9ba200a23026dd67",
            "4567a062b5d646d58d127e4e80d032db",
            "7547338a56eb4913b9184b9a2820caf3",
            "2f47e87377204b39937117eda124e396",
            "803e82d4652c4b9d9e6d1d67496c70ff",
            "499a3b73b62a4e6ab8eee8cb847f5064",
            "bfdcf6bd1f8e41b4b047f22fb662f27d",
            "11ab425d34ce4a69a31a1103853addac",
            "3137f39c6a9c4f91a95d581420007282",
            "1530d67637b4477486852b8172fa23b4",
            "08ba07bbcfc14b5cb4952e23cf597f3d",
            "4f7a74f5375b4ffab54c4ceae80ad92e",
            "8f3ff9f7d9f145bd83b7a3a1c768fe38",
            "6399fe66b332442f91e8a32795db243e",
            "b9eb0801148e4b079e81761b2399d8c5",
            "9150c3e5c95543d7b669f8f43b722bc4",
            "eb812316cb904c4fa3afdd1147a98f9e",
            "db5612ac772d42d1bad1d9819604b11a",
            "8c6620abccdc4196a1a687c7fade93d4",
            "438393bce4f44d039bdf99f790f15a08",
            "1d46e9cdaff9427b9473c2d7fafd46da",
            "45a229cd243b44378e6d6cec41b67e29",
            "7f3a92ebfb674b728dace8c65d2e4d8e",
            "e721f1cd62ae4733a10b2211a3b9cdad",
            "fdb5d5af48e7455f9d491957a34fb631",
            "7c8773208f1041d6800ec8c2bc29b4a8",
            "3c9d7b3d9d6c40069d5cc87136a5befb",
            "6f3c14b305da431d843dbc7bfccc6437",
            "c43785a67a774cdba8100a27f9a73da4",
            "ea592daaf0c64ea28a65e599842d0836",
            "47e6ab7ce4714e199f77a0446b75194a",
            "268e1d92ba354e7f8ae316080f6f782c",
            "e87f586eb2d649c7a61709b599e0d844",
            "7be911c77f4a46f5b88850d9c721a939",
            "ae5e6d9cb4604a0ea1acb31d790812da",
            "367df4ee61ed46bc9b1b36e09e538ee6",
            "b30cfcd8fa0b4d92bef0bf9a4794a212",
            "8359beed45404e4e896340ba3dcc21d5",
            "5a591fb8b65e43e19a96afb0eca3e736",
            "23994b84bf9e44008aaa7a837b18ed92",
            "d40c3feec19446bf805faa9b460dfbd2",
            "77b0cf0246b24f96930d580b17f4ba6f",
            "36eea7654e9b481fb964c9985e30eab5",
            "575110d2a655490e849c600f1ea6927c",
            "04672cddd7634e2cb4bb4296f90ad6f5",
            "8233357fab4e41f88d152714bdc0774c",
            "2530275a389f42e0a1c1f79eeedc58cd",
            "268ba618e40c416897f1c4b45a1b029d",
            "9c3c83c6f686431089d2e3ee36fcdd1e",
            "e2e3d116a8b84884b518c335c11ddcb5",
            "b58a4b6abbf74d45a5d418f53235dbd9",
            "764b10360b394a3ebc109e5624004730",
            "476c502581474954b0858b7b256d74c9",
            "ce823db654ad4ee78a0d46b50c77b4bb",
            "2e1ff9bca8114ffeadcc684b1224285c"
          ]
        },
        "outputId": "19166f04-7f4f-4f6a-beaf-636fbf7c4bac"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "model_name = \"tmills/roberta_sfda_sharpseed\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(model_name,output_hidden_states=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          config=config)\n",
        "\n",
        "fixed_source_net = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
        "                                                            config=config)\n",
        "fixed_source_net.cuda()\n",
        "for k,v in fixed_source_net.named_parameters():\n",
        "  v.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24d122dc41834ffb99b1ba0d9e371b90",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=563.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11ab425d34ce4a69a31a1103853addac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9150c3e5c95543d7b669f8f43b722bc4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e721f1cd62ae4733a10b2211a3b9cdad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "268e1d92ba354e7f8ae316080f6f782c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=818.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23994b84bf9e44008aaa7a837b18ed92",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=71.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "268ba618e40c416897f1c4b45a1b029d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501013463.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2RN47Cz_ngW"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def text_augmentation(lines,extra_size_ratio=5):\n",
        "  lt = 6\n",
        "  rt = 3\n",
        "  p = re.compile('<e>.*</e>')\n",
        "  concept_terms = []\n",
        "  for line in lines:\n",
        "    line=line[0]\n",
        "    concept_terms.append(re.findall('<e>.*</e>', line)[0])\n",
        "  for i in range(extra_size_ratio*len(lines)):\n",
        "    idx = random.choice(range(len(lines)))\n",
        "    line = lines[idx][0]\n",
        "    n=len(line)\n",
        "    ## taking only a part of sentence that contains the marked term with max 6 words on left and 3 word on right\n",
        "    m=p.search(line)\n",
        "    (start,end) = m.span()\n",
        "\n",
        "    # left = line[:start]\n",
        "    # left_words = left.split()\n",
        "    # left_words = left_words[-min(lt,len(left_words)):]\n",
        "    # left = ' '.join(left_words)\n",
        "\n",
        "    # right = line[end:]\n",
        "    # right_words = right.split()\n",
        "    # right_words = right_words[:min(rt,len(right_words))]\n",
        "    # right = ' '.join(right_words)\n",
        "\n",
        "    # new_line = left+\" \"+m.group()+\" \"+right\n",
        "    # lines.append([new_line])\n",
        "    ## --------\n",
        "    ## replacing concept term with some other concept term\n",
        "    idx2 = random.choice(range(len(concept_terms)))\n",
        "    new_line2 = line[:start] + concept_terms[idx2] + line[end:]\n",
        "    lines.append([new_line2])\n",
        "    ## -------\n",
        "    print(\"original line : \",line)\n",
        "    # print(\"new first line : \",new_line)\n",
        "    print(\"new second line : \",new_line2)\n",
        "  return lines\n",
        "\n",
        "class NegationDataset(Dataset):\n",
        "    def __init__(self, features):\n",
        "        self.features = features\n",
        "        self.label_list = [\"-1\", \"1\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, i) -> InputFeatures:\n",
        "        return self.features[i]\n",
        "\n",
        "    def get_labels(self):\n",
        "        return self.label_list\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def from_tsv(cls, tsv_file, tokenizer,flag=0):\n",
        "        \"\"\"Creates examples for the test set.\"\"\"\n",
        "        lines = DataProcessor._read_tsv(tsv_file)\n",
        "        # print(lines)\n",
        "        # if flag==1:\n",
        "        #   lines = text_augmentation(lines,1)\n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            \n",
        "            guid = 'instance-%d' % i\n",
        "            if line[0] in labels:\n",
        "                text_a = '\\t'.join(line[1:])\n",
        "            else:\n",
        "                text_a = '\\t'.join(line)\n",
        "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=None))\n",
        "\n",
        "        features = glue_convert_examples_to_features(\n",
        "            examples,\n",
        "            tokenizer,\n",
        "            max_length=max_length,\n",
        "            label_list=labels,\n",
        "            output_mode='classification',\n",
        "        )\n",
        "        return cls(features)\n",
        "train_dataset = NegationDataset.from_tsv('drive/My Drive/source-free-domain-adaptation/practice_text/negation/train.tsv', tokenizer,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyVRVTulLTOI"
      },
      "source": [
        "\n",
        "# ## not used removing stopwords right now in our task but can be tried\n",
        "\n",
        "# nltk.download('stopwords')\n",
        "# stopwords = stopwords.words('english')\n",
        "# lines = DataProcessor._read_tsv('drive/My Drive/source-free-domain-adaptation/practice_text/negation/train.tsv')\n",
        "# s = set([])\n",
        "# for line in lines:\n",
        "#   words =re.split(' |,',line[0])\n",
        "\n",
        "#   for word in words:\n",
        "#     if word.lower() in stopwords:\n",
        "#       s.add(word.lower())\n",
        "\n",
        "# print(s)\n",
        "# s=set(['about', 'now', 'having', 'through','but', 'has', 'down','these', 'any', 'few', 'before', 'most', 'against', 'in', 'this', 'too', 'an', 'were', 'she', 'it', 'if', 'a', 'up', 'once', 'be', 'from', 'only', 'then', 'their', 'have', 'can', 'we', 'had', 'the', 'his', 'that', 'doing', 'to', 'because', 'you', 'between', 'below', 'during', 'y', 'there', 'your', 'until', 'm', 'under', 'did', 'than','on', 'they', 'while', 'does', 'again', 'd', 'own', 'him', 'what', 'when', 'at','why', 'by', 'was', 'as', 'out', 'those', 'which', 'over', 'such', 's', 'same', 'will', 'each', 'very', 'after', 'being', 'himself', 't', 'her', 'i', 'who', 'so', 'is', 'should', 'some', 'other', 'of', 'all', 'above', 'am', 'he', 'here', 'been', 'are', 'just','where', 'off', 'do', 'more'])\n",
        "# ##-----------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR_pxbklIAZQ"
      },
      "source": [
        "\n",
        "## preprocesses inputs from the text that can be directly fed to model\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "output_label = []\n",
        "y_true = torch.tensor([]).cuda()\n",
        "for feat in train_dataset.features:\n",
        "  input_ids.append(feat.input_ids)\n",
        "  attention_masks.append(feat.attention_mask)\n",
        "  out = fixed_source_net(torch.tensor([feat.input_ids]).cuda(),torch.tensor([feat.attention_mask]).cuda())\n",
        "  y_true = torch.cat((y_true,torch.argmax(out[0],dim=1)),0)\n",
        "  # print(y_true)\n",
        "\n",
        "input_ids = torch.tensor(input_ids)\n",
        "attention_masks = torch.tensor(attention_masks)\n",
        "# pos_id = input_ids[y_true==1]\n",
        "# pos_mask = attention_masks[y_true==1]\n",
        "# neg_id = input_ids[y_true==0]\n",
        "# neg_mask = attention_masks[y_true==0]\n",
        "# pos_size = pos_id.shape[0]\n",
        "# negn = range(neg_id.shape[0])\n",
        "# idx = random.choices(negn,k=pos_size)\n",
        "# neg_red_id = neg_id[idx]\n",
        "# neg_red_mask = neg_mask[idx]\n",
        "# input_red_ids = torch.cat((pos_id,neg_red_id),0)\n",
        "# attention_red_mask = torch.cat((pos_mask,neg_red_mask),0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWJzDIkHvd4N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_crBYnQgOucr"
      },
      "source": [
        " \n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        " \n",
        "dataset = TensorDataset(input_ids, attention_masks)\n",
        "# dataset = TensorDataset(input_red_ids,attention_red_mask)\n",
        "# dataset.tensors\n",
        "batch_size=16 # 32\n",
        "train_dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            # sampler = RandomSampler(dataset), # Select batches randomly        ### was commented for 0.8759\n",
        "            shuffle = True,  ### not here for 0.8759\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "APM_dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size = 16 # T\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt1dJEsI0scc"
      },
      "source": [
        "\n",
        "def proto_augmentation(prototype_memory,prototype_memory_dict,num_prototype_,lb = 0.5,extra_size_ratio = 0.5):\n",
        "  prototype_memory = []\n",
        "  for cls in range(2):\n",
        "    extra_prototype = np.empty((0,768), np.float32)\n",
        "    l = prototype_memory_dict[cls]\n",
        "    \n",
        "    for i in range(int(extra_size_ratio*num_prototype_)):\n",
        "      idx=random.sample(range(num_prototype_),2)\n",
        "      new_prototype = (l[idx[1]]-l[idx[0]])*lb+l[idx[0]]\n",
        "      extra_prototype = np.append(extra_prototype,np.array([new_prototype]),axis=0)\n",
        "    prototype_memory_dict[cls] = np.concatenate((l,extra_prototype),axis = 0)\n",
        "    prototype_memory.append(prototype_memory_dict[cls])\n",
        "  num_prototype_ += int(extra_size_ratio*num_prototype_)\n",
        "  prototype_memory = np.concatenate(prototype_memory,axis=0)\n",
        "\n",
        "  return prototype_memory,prototype_memory_dict,num_prototype_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNwGf52B27HJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a191d05-1fc0-48cb-a96f-cc30a98004cd"
      },
      "source": [
        "\n",
        "import time\n",
        "print(len(dataset))\n",
        "def APM_ours(target_trainable_net):\n",
        "  target_trainable_net = target_trainable_net.cuda()\n",
        "\n",
        "  cnt=1\n",
        "  available_cls = []\n",
        "  h_dict = {}\n",
        "  feat_dict = {}\n",
        "  missing_cls = []\n",
        "  after_softmax_numpy_for_emergency = []\n",
        "  feature_numpy_for_emergency = []\n",
        "  max_prototype_bound = 100\n",
        "  start_time = time.time()\n",
        "  m=torch.nn.Softmax(dim=1)\n",
        "\n",
        "  for cls in range(2): ## number of classes and their cls\n",
        "    h_dict[cls] = []\n",
        "    feat_dict[cls] = []\n",
        "\n",
        "  for dt in APM_dataloader:\n",
        "    input_id = dt[0].cuda()\n",
        "    attention_mask = dt[1].cuda()\n",
        "\n",
        "    out = target_trainable_net(input_id,attention_mask=attention_mask)\n",
        "    \n",
        "    ### ?\n",
        "    fc1 = out[1][-1][:,0,:]\n",
        "    pred = m(out[0])\n",
        "\n",
        "    after_softmax_numpy_for_emergency.append(pred.cpu().detach().numpy())\n",
        "    feature_numpy_for_emergency.append(fc1.cpu().detach().numpy())\n",
        "    pseudo_label = torch.argmax(pred, dim=1)\n",
        "    pseudo_label = pseudo_label.cpu()\n",
        "    entropy = torch.sum(- pred * torch.log(pred), dim=1, keepdim=True)\n",
        "    entropy_norm = entropy / np.log(pred.size(1))\n",
        "    entropy_norm = entropy_norm.squeeze(1)\n",
        "    entropy_norm = entropy_norm.cpu()\n",
        "    # diff = -torch.abs(out[0][:,0] - out[0][:,1])\n",
        "    for cls in range(2):\n",
        "      # stack H for each class\n",
        "      cls_filter = (pseudo_label == cls)\n",
        "      list_loc = (torch.where(cls_filter == 1))[0]\n",
        "      num_element = list(list_loc.numpy())\n",
        "      if len(list_loc) == 0:\n",
        "          missing_cls.append(cls)\n",
        "          continue\n",
        "      available_cls.append(cls)\n",
        "      filtered_ent = torch.gather(entropy_norm, dim=0, index=list_loc)\n",
        "      filtered_feat = torch.gather(fc1.cpu(), dim=0, index=list_loc.unsqueeze(1).repeat(1, 768))\n",
        "      h_dict[cls].append(filtered_ent.detach().numpy())\n",
        "      feat_dict[cls].append(filtered_feat.cpu().detach().numpy())\n",
        "\n",
        "  available_cls = np.unique(available_cls)\n",
        "  # print(feat_dict[0],h_dict[0])\n",
        "  # print(feat_dict[1],h_dict[1])\n",
        "  prototype_memory = []\n",
        "  prototype_memory_dict = {}\n",
        "  after_softmax_numpy_for_emergency = np.concatenate(after_softmax_numpy_for_emergency, axis=0)\n",
        "  feature_numpy_for_emergency = np.concatenate(feature_numpy_for_emergency, axis=0)\n",
        "  max_top1_ent = 0\n",
        "  for cls in available_cls:\n",
        "    ents_np = np.concatenate(h_dict[cls], axis=0)\n",
        "    ent_idxs = np.argsort(ents_np)\n",
        "    top1_ent = ents_np[ent_idxs[0]]\n",
        "    if max_top1_ent < top1_ent:\n",
        "      max_top1_ent = top1_ent\n",
        "      max_top1_class = cls\n",
        "\n",
        "  class_protypeNum_dict = {}\n",
        "  max_prototype = 0\n",
        "  # max_prototype = 100\n",
        "  for cls in available_cls:\n",
        "    ents_np = np.concatenate(h_dict[cls], axis=0)\n",
        "    ents_np_filtered = (ents_np <= max_top1_ent)\n",
        "    class_protypeNum_dict[cls] = ents_np_filtered.sum()\n",
        "\n",
        "    if max_prototype < ents_np_filtered.sum():\n",
        "      max_prototype = ents_np_filtered.sum()\n",
        "\n",
        "  if max_prototype > max_prototype_bound:\n",
        "      max_prototype = max_prototype_bound\n",
        "\n",
        "  # print(feat_dict)\n",
        "  for cls in range(2):\n",
        "\n",
        "    if cls in available_cls:\n",
        "      ents_np = np.concatenate(h_dict[cls], axis=0)\n",
        "      \n",
        "      feats_np = np.concatenate(feat_dict[cls],axis=0)    # print(prototype_memory)xis=0)\n",
        "      # print(feat_dict[cls])\n",
        "      ent_idxs = np.argsort(ents_np)\n",
        "      # print(ent_idxs,class_protypeNum_dict[cls])\n",
        "    \n",
        "      # truncated_feat = feats_np[ent_idxs[:100]]\n",
        "      truncated_feat = feats_np[ent_idxs[:class_protypeNum_dict[cls]]]\n",
        "      fit_to_max_prototype = np.concatenate([truncated_feat] * (int(max_prototype / truncated_feat.shape[0]) + 1),\n",
        "                                            axis=0)\n",
        "      fit_to_max_prototype = fit_to_max_prototype[:max_prototype, :]\n",
        "      prototype_memory.append(fit_to_max_prototype)\n",
        "      prototype_memory_dict[cls] = fit_to_max_prototype\n",
        "    else:\n",
        "      after_softmax_torch_for_emergency = torch.Tensor(after_softmax_numpy_for_emergency)\n",
        "      emergency_idx = torch.argsort(after_softmax_torch_for_emergency, descending=True, dim=1)\n",
        "      cls_emergency_idx = emergency_idx[:, cls]\n",
        "      cls_emergency_idx = cls_emergency_idx[0]\n",
        "      cls_emergency_idx_numpy = cls_emergency_idx.data.numpy()\n",
        "\n",
        "      copied_features_emergency = np.concatenate(\n",
        "          [np.expand_dims(feature_numpy_for_emergency[cls_emergency_idx_numpy], axis=0)] * max_prototype, axis=0)\n",
        "\n",
        "      prototype_memory.append(copied_features_emergency)\n",
        "      prototype_memory_dict[cls] = copied_features_emergency\n",
        "\n",
        "  print(\"** APM update... time:\", time.time() - start_time)\n",
        "  \n",
        "  prototype_memory = np.concatenate(prototype_memory, axis=0) ## check\n",
        "  num_prototype_ = int(max_prototype)\n",
        "  # print(num_prototype_,prototype_memory_dict,prototype_memory)\n",
        "  return prototype_memory, num_prototype_, prototype_memory_dict\n",
        "\n",
        "fixed_source_net.cuda()\n",
        "# prototype_memory, num_prototype_, prototype_memory_dict = APM_ours(fixed_source_net)\n",
        "# prototype_memory,prototype_memory_dict,num_prototype_ = proto_augmentation(prototype_memory,prototype_memory_dict,num_prototype_)\n",
        "\n",
        "def check_if_updated(model1,model2):\n",
        "  a=target_trainable_net.roberta.encoder.layer[10].attention.output.dense.weight\n",
        "  b=fixed_source_net.roberta.encoder.layer[10].attention.output.dense.weight\n",
        "  if np.array_equal(a.cpu().detach().numpy(),b.cpu().detach().numpy()):\n",
        "    print(\"same\")\n",
        "  else:\n",
        "    print(\"different\")\n",
        "\n",
        "# check_if_updated(fixed_source_net,target_trainable_net)\n",
        "# del prototype_memory \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztC5C05nvRnS"
      },
      "source": [
        "import math\n",
        "def op_copy(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr0'] = param_group['lr']\n",
        "    return optimizer\n",
        "\n",
        "def lr_scheduler(optimizer, iter_num, max_iter, gamma=10, power=0.75):\n",
        "    decay = (1 + gamma * iter_num / max_iter) ** (-power)\n",
        "    # decay = 1/math.sqrt(iter_num)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = param_group['lr0'] * decay\n",
        "        param_group['weight_decay'] =0.0005\n",
        "        param_group['momentum'] = 0.9\n",
        "        param_group['nesterov'] = True\n",
        "    return optimizer\n",
        "\n",
        "def tensor_l2normalization(q):\n",
        "    qn = torch.norm(q, p=2, dim=1).detach().unsqueeze(1)\n",
        "    q = q.div(qn.expand_as(q))\n",
        "    return q\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAvKGkOtfPcb"
      },
      "source": [
        "import copy \n",
        "model_name = \"tmills/roberta_sfda_sharpseed\"\n",
        "# del config1,tokenizer1,target_trainable_net\n",
        "config1 = AutoConfig.from_pretrained(model_name,output_hidden_states=True)\n",
        "tokenizer1 = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          config=config1)\n",
        "\n",
        "target_trainable_net = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
        "                                                            config=config1)\n",
        "target_trainable_net = target_trainable_net.cuda()\n",
        "class classifier_head(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      # self.dense = nn.Linear(in_features = 768,out_features = 768,bias=True)\n",
        "      self.dense = copy.deepcopy(target_trainable_net.classifier.dense)\n",
        "      # self.dropout = nn.Dropout(p=0.1, inplace = False)\n",
        "      self.dropout = copy.deepcopy(target_trainable_net.classifier.dropout)\n",
        "      # self.out_proj = nn.Linear(in_features = 768, out_features = 2,bias=True)\n",
        "      self.out_proj = copy.deepcopy(target_trainable_net.classifier.out_proj)\n",
        "  def forward(self, x):\n",
        "      # take <s> token (equiv. to [CLS])\n",
        "      # x = feature[:,0,:]\n",
        "      x = self.dropout(x)\n",
        "      x = self.dense(x)\n",
        "      x = torch.tanh(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.out_proj(x)\n",
        "      return x\n",
        "\n",
        "classifier = classifier_head()\n",
        "classifier = classifier.cuda() ### change"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwUq6HycR8Rc"
      },
      "source": [
        "# for k,v in target_trainable_net.named_parameters():\n",
        "#   a = k.split(\".\")\n",
        "#   if a[0]!=\"classifier\" and a[1] not in [\"embeddings\",\"pooler\"] and int(a[3])<=8:\n",
        "#     v.requires_grad = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1NV5ScldjM1"
      },
      "source": [
        "\n",
        "def load_testdata():\n",
        "    test_dataset = NegationDataset.from_tsv('drive/My Drive//source-free-domain-adaptation/practice_text/negation/dev.tsv', tokenizer)\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for feat in test_dataset.features:\n",
        "        input_ids.append(feat.input_ids)\n",
        "        attention_masks.append(feat.attention_mask)\n",
        "\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "    print(input_ids.shape,attention_masks.shape)\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_masks,torch.arange(input_ids.size(0)))\n",
        "    \n",
        "    # batch_size=32 # 32\n",
        "    test_dataloader = DataLoader(dataset, batch_size = batch_size)\n",
        "    print(batch_size)\n",
        "    return test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwwbVmX6dlH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6985bb7-a3aa-4738-92bc-fa887369f543"
      },
      "source": [
        "test_dataloader = load_testdata()\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score,confusion_matrix\n",
        "\n",
        "\n",
        "squarer = lambda t: 1 if t>1 else 0\n",
        "vfunc = np.vectorize(squarer)\n",
        "def evaluation(test_dataloader,target_net,fixed_source_net,flag=0):\n",
        "    \n",
        " \n",
        "    if flag == 1:\n",
        "      pred1 = np.array([])\n",
        "      for itr in range(3,6):\n",
        "        start=True\n",
        "        target_net = AutoModelForSequenceClassification.from_pretrained('drive/My Drive/models_APM/'+'1_'+str(itr)+'/').cuda()\n",
        "        for data in test_dataloader:\n",
        "            out = target_net(data[0].cuda(),data[1].cuda())\n",
        "            if start:\n",
        "                predict = out[0].cpu().detach().numpy()\n",
        "                start = False\n",
        "            else:\n",
        "                predict = np.concatenate((predict,out[0].cpu().detach().numpy()))\n",
        "        predict = np.argmax(predict,1)\n",
        "        print(predict)\n",
        "        if itr==3:\n",
        "          pred1 = predict\n",
        "        else:\n",
        "          pred1 = np.vstack([pred1,predict])\n",
        "      \n",
        "      predict = pred1.sum(axis=0)\n",
        "      predict = vfunc(predict)\n",
        "      print(predict)\n",
        "    else:\n",
        "      start=True\n",
        "      # target_net = AutoModelForSequenceClassification.from_pretrained('drive/My Drive/models_APM/'+str(itr)+'_3/').cuda()\n",
        "      for data in test_dataloader:\n",
        "          out = target_net(data[0].cuda(),data[1].cuda())\n",
        "          if start:\n",
        "              predict = out[0].cpu().detach().numpy()\n",
        "              start = False\n",
        "          else:\n",
        "              predict = np.concatenate((predict,out[0].cpu().detach().numpy()))\n",
        "      predict = np.argmax(predict,1)\n",
        "    # print(predict.shape)\n",
        "\n",
        "    fixed_source_net = fixed_source_net.cuda()\n",
        "    fixed_source_net.eval()\n",
        "    start=True\n",
        "    for data in test_dataloader:\n",
        "        out1 = fixed_source_net(data[0].cuda(),data[1].cuda())\n",
        "        if start:\n",
        "            predict1 = out1[0].cpu().detach().numpy()\n",
        "            start = False\n",
        "        else:\n",
        "            predict1 = np.concatenate((predict1,out1[0].cpu().detach().numpy()))\n",
        "    predict1 = np.argmax(predict1,1)\n",
        "    # print(predict1.shape)\n",
        " \n",
        "    pred = np.array([0]*5545)\n",
        "    for i in range(5545):\n",
        "        pred[i] = labels[predict[i]]\n",
        "    # print(pred.shape)\n",
        " \n",
        "    pred1 = np.array([0]*5545)\n",
        "    for i in range(5545):\n",
        "        pred1[i] = labels[predict1[i]]\n",
        "    # print(pred1.shape)\n",
        "    \n",
        "    test_true = np.loadtxt('drive/My Drive//source-free-domain-adaptation/practice_text/negation/dev_labels.txt',dtype=np.int32)\n",
        "    # confusion_matrix(test_true,pred1),\n",
        "    # ,confusion_matrix(test_true,pred)\n",
        "    \n",
        "    trainable_f1_score = f1_score(test_true,pred)\n",
        "    trainable_prec = precision_score(test_true,pred)\n",
        "    trainable_recall = recall_score(test_true,pred)\n",
        "    scores = [['pretrained',f1_score(test_true,pred1),precision_score(test_true,pred1),recall_score(test_true,pred1)],\n",
        "              ['trained',trainable_f1_score,trainable_prec,trainable_recall]]\n",
        "    print(tabulate(scores,headers=['model','f1 score','precision','recall']))\n",
        "    print(confusion_matrix(test_true,pred))\n",
        "    print(confusion_matrix(test_true,pred1))\n",
        "    return trainable_f1_score,trainable_prec,trainable_recall\n",
        "\n",
        "  \n",
        "def forward(y_logits, y_true):\n",
        "    beta = 1\n",
        "    epsilon = 1e-15\n",
        "    # print(y_logits)\n",
        "    y_pred = torch.sigmoid(y_logits)\n",
        "    # m=torch.nn.Softmax(dim=1)\n",
        "    # y_pred = m(y_logits)\n",
        "    # print(y_pred)\n",
        "    \n",
        "    TP = (y_pred * y_true).sum(dim=1)\n",
        "    FP = (y_pred * (1-y_true)).sum(dim=1)\n",
        "    FN = ((1-y_pred) *  y_true).sum(dim=1)\n",
        "    fbeta = (1 + beta**2) * TP / ((1 + beta**2) * TP + (beta**2) * FN + FP + epsilon)\n",
        "    fbeta = fbeta.clamp(min=epsilon, max=1 - epsilon)\n",
        "    return 1 - fbeta.mean()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5545, 128]) torch.Size([5545, 128])\n",
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpqJ30x9US_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be29c2bd-4da1-46e5-bc02-b8c2be5c597b"
      },
      "source": [
        "## training portion of the code\n",
        "from torch.autograd import Variable\n",
        "import copy \n",
        "import math\n",
        "# def target_train(train_lr,train_update_freq):\n",
        "fscores = np.zeros((5,5))\n",
        "precs  = np.zeros((5,5))\n",
        "recalls = np.zeros((5,5))\n",
        "for itr in range(5):\n",
        "  del target_trainable_net,classifier\n",
        "  target_trainable_net = AutoModelForSequenceClassification.from_pretrained(model_name,config=config1)\n",
        "  target_trainable_net = target_trainable_net.cuda()\n",
        "  classifier = classifier_head()\n",
        "  classifier = classifier.cuda()\n",
        "  # for k,v in target_trainable_net.named_parameters():\n",
        "  #   x = k.split('.')\n",
        "  #   if x[0]=='classifier':\n",
        "  #     v.requires_grad=False\n",
        "\n",
        "\n",
        "  train_start_time=time.time()\n",
        "\n",
        "  train_min_step = 180*5 ### 1000 originally\n",
        "  train_lr=0.0005\n",
        "  train_weight_decay = 0.0005\n",
        "  train_momentum = 0.9\n",
        "  train_update_freq = 96 #96 # changed from 10\n",
        "\n",
        "  # target_trainable_net.train()\n",
        "  optimizer = optim.SGD(list(filter(lambda p: p.requires_grad, target_trainable_net.parameters()))+list(classifier.parameters()), \n",
        "                        lr=train_lr, weight_decay=train_weight_decay, momentum=train_momentum, nesterov=True)\n",
        "\n",
        "  optimizer = op_copy(optimizer)\n",
        "  global_step = 0\n",
        "  best_acc = 0\n",
        "  best_epoch = 0\n",
        "  epoch_id = 0\n",
        "  class_num =  2\n",
        "  max_epoch = math.ceil((train_min_step*batch_size)/len(dataset))\n",
        "  pt_memory_update_frequncy =  train_update_freq\n",
        "  # eval_interval = 100\n",
        "  cnt=0\n",
        "  m=torch.nn.Softmax(dim=1)\n",
        "\n",
        "  fixed_source_net.train()\n",
        "  classifier.train()\n",
        "\n",
        "  fixed_source_net.zero_grad()\n",
        "  classifier.zero_grad()\n",
        "  target_trainable_net.zero_grad()\n",
        "\n",
        "  while global_step < train_min_step:\n",
        "    epoch_id += 1\n",
        "    max_iter = max_epoch * len(train_dataloader)\n",
        "    print(max_iter)\n",
        "    epoch_start_time=time.time()\n",
        "\n",
        "    for i, dt in enumerate(train_dataloader):\n",
        "      # APM init/update\n",
        "      if (global_step) % pt_memory_update_frequncy == 0: ### change\n",
        "          target_trainable_net.eval() ### change\n",
        "          prototype_memory, num_prototype_,prototype_memory_dict = APM_ours(target_trainable_net)\n",
        "          # prototype_memory,prototype_memory_dict,num_prototype_ = proto_augmentation(prototype_memory,prototype_memory_dict,num_prototype_) # Tried augmentation in prototype feature\n",
        "\n",
        "      input_id = dt[0].cuda()\n",
        "      attention_mask = dt[1].cuda()\n",
        "      \n",
        "      fixed_source_net.train()\n",
        "      out_s = fixed_source_net(input_id,attention_mask=attention_mask)\n",
        "      pseudo_label_s = torch.argmax(out_s[0], dim=1).cuda()\n",
        "      pseudo_label_hot_s = torch.zeros(out_s[0].shape).cuda()\n",
        "      pseudo_label_hot_s = pseudo_label_hot_s.scatter(1,pseudo_label_s.unsqueeze(1),1.0).cuda()\n",
        "      ## trainable target model\n",
        "      target_trainable_net.train()\n",
        "      out_t = target_trainable_net(input_id,attention_mask=attention_mask)\n",
        "      fc_t = out_t[1][-1][:,0,:] #target_trainable_net.roberta.pooler(out_t[1][-1])\n",
        "      feature_embed_tensor = fc_t.cpu()\n",
        "      \n",
        "      \n",
        "      logit_s2t = classifier(fc_t) ### change\n",
        "      logit_t = out_t[0]\n",
        "\n",
        "      \n",
        "\n",
        "      proto_feat_tensor = torch.Tensor(prototype_memory)\n",
        "      proto_feat_tensor = tensor_l2normalization(proto_feat_tensor)\n",
        "      batch_feat_tensor = tensor_l2normalization(feature_embed_tensor)\n",
        "\n",
        "      sim_mat = torch.mm(batch_feat_tensor, proto_feat_tensor.permute(1,0))\n",
        "      sim_mat = F.avg_pool1d(sim_mat.unsqueeze(0), kernel_size=num_prototype_, stride=num_prototype_).squeeze(0)# (B, #class)\n",
        "      \n",
        "\n",
        "      pseudo_label_t = torch.argmax(sim_mat, dim=1).cuda()\n",
        "      # pseudo_label_hot_t = torch.zeros(sim_mat.shape).scatter(1,a.unsqueeze(1),1.0).cuda()\n",
        "      if not np.array_equal(pseudo_label_t.cpu().detach().numpy(),pseudo_label_s.cpu().detach().numpy()):\n",
        "        # print(sim_mat,logit_t,pseudo_label_s,pseudo_label_t)\n",
        "        cnt=cnt+1\n",
        "      # lr_scheduler(optimizer, iter_num=global_step, max_iter=max_iter)\n",
        "\n",
        "      # confidence-based filtering\n",
        "      arg_idxs = torch.argsort(sim_mat, dim=1, descending=True) # (B, #class)\n",
        "      first_group_idx = arg_idxs[:, 0]\n",
        "      second_group_idx = arg_idxs[:, 1]\n",
        "      first_group_feat = [prototype_memory_dict[int(x.numpy())] for x in first_group_idx]\n",
        "      first_group_feat_tensor = torch.tensor(np.concatenate(first_group_feat, axis=0)) # (B*P, 2048)\n",
        "      first_group_feat_tensor = tensor_l2normalization(first_group_feat_tensor)\n",
        "\n",
        "      second_group_feat = [prototype_memory_dict[int(x.numpy())] for x in second_group_idx]\n",
        "      second_group_feat_tensor = torch.tensor(np.concatenate(second_group_feat, axis=0)) # (B*P, 2048)\n",
        "      second_group_feat_tensor = tensor_l2normalization(second_group_feat_tensor)\n",
        "\n",
        "      feature_embed_tensor_repeat = torch.Tensor(np.repeat(feature_embed_tensor.cpu().detach().numpy(), repeats=num_prototype_, axis=0))\n",
        "      feature_embed_tensor_repeat = tensor_l2normalization(feature_embed_tensor_repeat)\n",
        "\n",
        "      first_dist_mat = 1 - torch.mm(first_group_feat_tensor, feature_embed_tensor_repeat.permute(1,0)) # distance = 1  - simialirty\n",
        "      second_dist_mat = 1 - torch.mm(second_group_feat_tensor, feature_embed_tensor_repeat.permute(1,0))\n",
        "\n",
        "      first_dist_mat = F.max_pool2d(first_dist_mat.permute(1,0).unsqueeze(0).unsqueeze(0), kernel_size=num_prototype_, stride=num_prototype_).squeeze(0).squeeze(0)# (B, #class)\n",
        "      second_dist_mat = -1*F.max_pool2d(-1* second_dist_mat.permute(1,0).unsqueeze(0).unsqueeze(0), kernel_size=num_prototype_, stride=num_prototype_).squeeze(0).squeeze(0)# (B, #class)\n",
        "\n",
        "      first_dist_vec = torch.diag(first_dist_mat) #(B)\n",
        "      second_dist_vec = torch.diag(second_dist_mat) # B\n",
        "      confidence_mask = ((first_dist_vec- second_dist_vec) < 0).cuda()\n",
        "      \n",
        "      \n",
        "      # optimize target network using two types of pseudo labels\n",
        "      ce_from_s2t = nn.CrossEntropyLoss()(logit_s2t,pseudo_label_s)\n",
        "      # ce_from_s2t = forward(logit_t,pseudo_label_hot_s)\n",
        "      # ce_from_s2t = nn.CrossEntropyLoss(reduction = 'none')(logit_t, pseudo_label_s).view(-1,1).squeeze(1)\n",
        "      # ones = pseudo_label_s.sum(axis=0)\n",
        "      # zeros = 16-ones\n",
        "      # # # print(ce_from_s2t)\n",
        "      # # # print(ones)\n",
        "      # # # print(zeros)\n",
        "      # # # print(pseudo_label_s)\n",
        "      # # # print(1-pseudo_label_s)\n",
        "      # # # print(torch.mean(ce_from_s2t*pseudo_label_s,dim=0,keepdim=True)*(16/ones))\n",
        "      # # # print(torch.mean(ce_from_s2t*(1-pseudo_label_s),dim=0,keepdim=True)*(16/zeros))\n",
        "      # if ones!=0 and zeros!=0:\n",
        "      #   ce_from_s2t = (torch.mean(ce_from_s2t*pseudo_label_s,dim=0,keepdim=True)*(16/ones)+torch.mean(ce_from_s2t*(1-pseudo_label_s),dim=0,keepdim=True)*(16/zeros))/2\n",
        "      # else:\n",
        "      #   ce_from_s2t = torch.mean(ce_from_s2t, dim=0, keepdim=True)\n",
        "      # ce_from_s2t = nn.CrossEntropyLoss()(logit_t, pseudo_label_s)\n",
        "      \n",
        "      ce_from_t = nn.CrossEntropyLoss(reduction='none')(logit_t, pseudo_label_t).view(-1, 1).squeeze(1)\n",
        "      ce_from_t = torch.mean(ce_from_t*confidence_mask, dim=0, keepdim=True)*(16/confidence_mask.sum(axis=0))\n",
        "      \n",
        "      alpha = np.float(2.0 / (1.0 + np.exp( -0.08* global_step / float(train_min_step//2))) - 1.0)   ### 0.8 for 0.8759 ## changed from -0.08 to -0.8\n",
        "      # alpha = 0\n",
        "      # ce_total = ce_from_s2t\n",
        "      ce_total = (1 - alpha)*ce_from_s2t + alpha*ce_from_t\n",
        "      if global_step%2==0:\n",
        "        batch_loss = ce_total\n",
        "      else:\n",
        "        batch_loss+=ce_total\n",
        "      global_step+=1 \n",
        "      if global_step%2==0:\n",
        "        lr_scheduler(optimizer, iter_num=global_step, max_iter=max_iter)\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss /= 2\n",
        "        batch_loss.backward(retain_graph=True)\n",
        "        # print(global_step,batch_loss)\n",
        "        optimizer.step()\n",
        "      # optimizer.zero_grad()\n",
        "      # # # ce_from_s2t.backward(retain_graph=True)\n",
        "      # ce_total.backward(retain_graph=True)\n",
        "      # optimizer.step()\n",
        "      # print(global_step,ce_from_s2t.cpu().detach().numpy())\n",
        "      # print(global_step,alpha,ce_total.cpu().detach().numpy(),ce_from_s2t.cpu().detach().numpy(),ce_from_t.cpu().detach().numpy())\n",
        "      # global_step+=1\n",
        "\n",
        "\n",
        "    epoch_end_time=time.time()\n",
        "    print(\"time taken for epoch no. {} is {}\".format(epoch_id,epoch_end_time-epoch_start_time))\n",
        "    print(global_step)\n",
        "    target_trainable_net.eval()\n",
        "    fixed_source_net.eval()\n",
        "    fscore,prec,recall = evaluation(test_dataloader,target_trainable_net,fixed_source_net)\n",
        "    fscores[itr][epoch_id-1] = fscore\n",
        "    precs[itr][epoch_id-1] = prec\n",
        "    recalls[itr][epoch_id-1] = recall\n",
        "\n",
        "    # avg_acc[epoch_id]+=acc\n",
        "\n",
        "    target_trainable_net.save_pretrained('drive/My Drive/models_without_APM/'+str(itr)+'_'+str(epoch_id)+'/')\n",
        "    tokenizer1.save_pretrained('drive/My Drive/models_without_APM/'+str(itr)+'_'+str(epoch_id)+'/')\n",
        "    # if epoch_id == 3:\n",
        "    #   break\n",
        "    \n",
        "  #   if acc>best_acc:\n",
        "  #     best_acc=acc\n",
        "  #     best_epoch = epoch_id\n",
        "  #     target_trainable_net.save_pretrained(\"drive/My Drive/best_model2\")\n",
        "  #     tokenizer1.save_pretrained(\"drive/My Drive/best_model2\")\n",
        "    \n",
        "  print(cnt)\n",
        "  train_end_time = time.time()\n",
        "  print(\"Total_time taken : \",train_end_time-train_start_time)\n",
        "\n",
        "print(fscores)\n",
        "print(precs)\n",
        "print(recalls)\n",
        "# print(avg_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "905\n",
            "** APM update... time: 21.153208017349243\n",
            "** APM update... time: 20.900434017181396\n",
            "time taken for epoch no. 1 is 149.54033708572388\n",
            "181\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.866508     0.921212  0.817937\n",
            "[[4352   78]\n",
            " [ 203  912]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 21.058149099349976\n",
            "** APM update... time: 20.93165898323059\n",
            "time taken for epoch no. 2 is 148.46271228790283\n",
            "362\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.854119     0.877127  0.832287\n",
            "[[4300  130]\n",
            " [ 187  928]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.975208282470703\n",
            "** APM update... time: 20.93445658683777\n",
            "time taken for epoch no. 3 is 148.61382412910461\n",
            "543\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.847597     0.865421  0.830493\n",
            "[[4286  144]\n",
            " [ 189  926]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.935330629348755\n",
            "** APM update... time: 20.943479776382446\n",
            "time taken for epoch no. 4 is 148.2902021408081\n",
            "724\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.848235     0.86773   0.829596\n",
            "[[4289  141]\n",
            " [ 190  925]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.96333932876587\n",
            "** APM update... time: 20.900232315063477\n",
            "time taken for epoch no. 5 is 148.28803205490112\n",
            "905\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.850575     0.872642  0.829596\n",
            "[[4295  135]\n",
            " [ 190  925]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "393\n",
            "Total_time taken :  1161.6095399856567\n",
            "905\n",
            "** APM update... time: 20.947628021240234\n",
            "** APM update... time: 20.95230722427368\n",
            "time taken for epoch no. 1 is 148.5626630783081\n",
            "181\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.849703     0.865922  0.834081\n",
            "[[4286  144]\n",
            " [ 185  930]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.90262007713318\n",
            "** APM update... time: 20.958723068237305\n",
            "time taken for epoch no. 2 is 148.31525230407715\n",
            "362\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.858205     0.890927  0.827803\n",
            "[[4317  113]\n",
            " [ 192  923]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.933385610580444\n",
            "** APM update... time: 20.952592611312866\n",
            "time taken for epoch no. 3 is 148.04861974716187\n",
            "543\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.852941     0.874647  0.832287\n",
            "[[4297  133]\n",
            " [ 187  928]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.945857286453247\n",
            "** APM update... time: 20.951660871505737\n",
            "time taken for epoch no. 4 is 150.17292833328247\n",
            "724\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.856486     0.879131  0.834978\n",
            "[[4302  128]\n",
            " [ 184  931]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.97619891166687\n",
            "** APM update... time: 20.959011793136597\n",
            "time taken for epoch no. 5 is 147.81985425949097\n",
            "905\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.861111     0.889952  0.834081\n",
            "[[4315  115]\n",
            " [ 185  930]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "356\n",
            "Total_time taken :  1156.6956629753113\n",
            "905\n",
            "** APM update... time: 20.865711450576782\n",
            "** APM update... time: 20.917404413223267\n",
            "time taken for epoch no. 1 is 150.1761441230774\n",
            "181\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.86236      0.902057  0.826009\n",
            "[[4330  100]\n",
            " [ 194  921]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.899441480636597\n",
            "** APM update... time: 20.90649175643921\n",
            "time taken for epoch no. 2 is 148.8350532054901\n",
            "362\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.853321     0.878443  0.829596\n",
            "[[4302  128]\n",
            " [ 190  925]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.949646472930908\n",
            "** APM update... time: 20.938076734542847\n",
            "time taken for epoch no. 3 is 150.0052809715271\n",
            "543\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.857143     0.890716  0.826009\n",
            "[[4317  113]\n",
            " [ 194  921]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 21.034791469573975\n",
            "** APM update... time: 20.945723295211792\n",
            "time taken for epoch no. 4 is 150.6274871826172\n",
            "724\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.854512     0.877956  0.832287\n",
            "[[4301  129]\n",
            " [ 187  928]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 21.02028512954712\n",
            "** APM update... time: 20.960972547531128\n",
            "time taken for epoch no. 5 is 149.85583901405334\n",
            "905\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.851631     0.872881  0.83139\n",
            "[[4295  135]\n",
            " [ 188  927]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "368\n",
            "Total_time taken :  1164.9984951019287\n",
            "905\n",
            "** APM update... time: 20.930980920791626\n",
            "** APM update... time: 21.024824142456055\n",
            "time taken for epoch no. 1 is 149.2053737640381\n",
            "181\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.837461     0.840868  0.834081\n",
            "[[4254  176]\n",
            " [ 185  930]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.91237998008728\n",
            "** APM update... time: 20.92948603630066\n",
            "time taken for epoch no. 2 is 150.4526925086975\n",
            "362\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.858065     0.882464  0.834978\n",
            "[[4306  124]\n",
            " [ 184  931]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.93693518638611\n",
            "** APM update... time: 20.96822214126587\n",
            "time taken for epoch no. 3 is 148.94517612457275\n",
            "543\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.853726     0.876298  0.832287\n",
            "[[4299  131]\n",
            " [ 187  928]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.98598837852478\n",
            "** APM update... time: 21.00412893295288\n",
            "time taken for epoch no. 4 is 149.38379001617432\n",
            "724\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.857275     0.88381   0.832287\n",
            "[[4308  122]\n",
            " [ 187  928]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.93595004081726\n",
            "** APM update... time: 20.678552865982056\n",
            "time taken for epoch no. 5 is 148.3564133644104\n",
            "905\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.859519     0.886559  0.834081\n",
            "[[4311  119]\n",
            " [ 185  930]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "354\n",
            "Total_time taken :  1159.0503871440887\n",
            "905\n",
            "** APM update... time: 20.660396814346313\n",
            "** APM update... time: 20.719300746917725\n",
            "time taken for epoch no. 1 is 149.0089201927185\n",
            "181\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.865142     0.901751  0.83139\n",
            "[[4329  101]\n",
            " [ 188  927]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.830381870269775\n",
            "** APM update... time: 20.949833154678345\n",
            "time taken for epoch no. 2 is 150.1570529937744\n",
            "362\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.870466     0.916667  0.8287\n",
            "[[4346   84]\n",
            " [ 191  924]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.9698224067688\n",
            "** APM update... time: 20.83428716659546\n",
            "time taken for epoch no. 3 is 150.66462683677673\n",
            "543\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.859813     0.897561  0.825112\n",
            "[[4325  105]\n",
            " [ 195  920]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.715622425079346\n",
            "** APM update... time: 20.765525579452515\n",
            "time taken for epoch no. 4 is 148.29152059555054\n",
            "724\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.862118     0.906931  0.821525\n",
            "[[4336   94]\n",
            " [ 199  916]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "905\n",
            "** APM update... time: 20.760343313217163\n",
            "** APM update... time: 21.01467537879944\n",
            "time taken for epoch no. 5 is 150.93221139907837\n",
            "905\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.852174     0.870093  0.834978\n",
            "[[4291  139]\n",
            " [ 184  931]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "361\n",
            "Total_time taken :  1161.0977358818054\n",
            "[[0.86650831 0.85411873 0.84759725 0.84823475 0.85057471]\n",
            " [0.84970306 0.85820549 0.85294118 0.85648574 0.86111111]\n",
            " [0.86235955 0.85332103 0.85714286 0.85451197 0.85163068]\n",
            " [0.8374606  0.85806452 0.85372585 0.85727483 0.85951941]\n",
            " [0.86514232 0.87046632 0.85981308 0.86211765 0.85217391]]\n",
            "[[0.92121212 0.87712665 0.86542056 0.86772983 0.87264151]\n",
            " [0.86592179 0.89092664 0.87464656 0.87913126 0.88995215]\n",
            " [0.90205681 0.87844255 0.89071567 0.87795648 0.87288136]\n",
            " [0.84086799 0.88246445 0.87629839 0.88380952 0.88655863]\n",
            " [0.90175097 0.91666667 0.89756098 0.90693069 0.87009346]]\n",
            "[[0.81793722 0.832287   0.83049327 0.82959641 0.82959641]\n",
            " [0.83408072 0.82780269 0.832287   0.83497758 0.83408072]\n",
            " [0.82600897 0.82959641 0.82600897 0.832287   0.83139013]\n",
            " [0.83408072 0.83497758 0.832287   0.832287   0.83408072]\n",
            " [0.83139013 0.82869955 0.82511211 0.82152466 0.83497758]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAiADYw1rFAV"
      },
      "source": [
        "# # lrs = [0.003,0.001,0.005,0.008]\n",
        "# # APM_update_freqs = [100,50,200]\n",
        "# # best_acc=0\n",
        "# # best_config = ()\n",
        "# # for lr in lrs:\n",
        "# #   for freq in APM_update_freqs:\n",
        "# #     acc,epoch = target_train(lr,freq)\n",
        "# #     print(lr,freq,epoch,acc)\n",
        "# #     if acc>best_acc:\n",
        "# #       best_acc=acc\n",
        "# #       best_config = (lr,freq,epoch)\n",
        "\n",
        "# # print(best_config,best_acc)\n",
        "\n",
        "# target_trainable_net.eval()\n",
        "# fixed_source_net.eval()\n",
        "# evaluation(test_dataloader,target_trainable_net,fixed_source_net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgU0Z9N7vmpC"
      },
      "source": [
        "# target_trainable_net.save_pretrained(\"drive/My Drive/best_model_without_APM_0.8624\")\n",
        "# tokenizer1.save_pretrained(\"drive/My Drive/best_model_without_APM_0.8624\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-kf68ew_X8O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}