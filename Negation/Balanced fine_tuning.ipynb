{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Balanced fine_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d4c00cdedd8745ac97977aeb141af97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b98670561ff84dd7a041b27bb612919f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b71a6a876d5e45da9a93c5f2dbdd7207",
              "IPY_MODEL_2572dbd5395a4bb6a5f0d797e3ab2a44"
            ]
          }
        },
        "b98670561ff84dd7a041b27bb612919f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b71a6a876d5e45da9a93c5f2dbdd7207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b3e9cffa3dba4612945307e7c844ae46",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 563,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 563,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3fdf569edbc45e1bac28f8e93b6061d"
          }
        },
        "2572dbd5395a4bb6a5f0d797e3ab2a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_978902007d224b2aa8f1e284ac07edc7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 563/563 [00:36&lt;00:00, 15.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52c7fdbd3e2c410a9bdc606944627eb5"
          }
        },
        "b3e9cffa3dba4612945307e7c844ae46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3fdf569edbc45e1bac28f8e93b6061d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "978902007d224b2aa8f1e284ac07edc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52c7fdbd3e2c410a9bdc606944627eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10a29cdb590b405591c13548991610ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_267611b7ac7f485081c15079c2f71538",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2de6ad602dfa4fc19d4c1062dab6d2fa",
              "IPY_MODEL_25b6f3d4dbb54b8d970680f9116a4d06"
            ]
          }
        },
        "267611b7ac7f485081c15079c2f71538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2de6ad602dfa4fc19d4c1062dab6d2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dc3aefa9ef894c288a90109aae5c5ace",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898822,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898822,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f15293da54b74c9a800745730ebadea7"
          }
        },
        "25b6f3d4dbb54b8d970680f9116a4d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1db1c8e6da5a4a1a9ec9795172445e37",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:09&lt;00:00, 99.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d6d86c6b4574d2e9b1578cbcdd1a899"
          }
        },
        "dc3aefa9ef894c288a90109aae5c5ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f15293da54b74c9a800745730ebadea7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1db1c8e6da5a4a1a9ec9795172445e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d6d86c6b4574d2e9b1578cbcdd1a899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae83ef14db0842e8a725fe6840bcb0ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0cff9c073fbf491bb265674d1c1bbab8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51ca5bd65ca64e9f8f2194df5cc555f2",
              "IPY_MODEL_c854d1511d734feb9bc4cd34205e1c55"
            ]
          }
        },
        "0cff9c073fbf491bb265674d1c1bbab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51ca5bd65ca64e9f8f2194df5cc555f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c54a1ee38acd43c99d109f6c23248260",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f1f442a8ebf4229a7769f59d1b3dca3"
          }
        },
        "c854d1511d734feb9bc4cd34205e1c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_142b4991d97f4ce0a79a4c202e5bd6fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:04&lt;00:00, 113kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77969fa047ec4e078d33764f839e3022"
          }
        },
        "c54a1ee38acd43c99d109f6c23248260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f1f442a8ebf4229a7769f59d1b3dca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "142b4991d97f4ce0a79a4c202e5bd6fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77969fa047ec4e078d33764f839e3022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3c96774e1c34fb0b284b730d49b370c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f4bf7dccdb5547c5a26494b129714d6f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e1b82306141c4f3c943cc4eed66bf208",
              "IPY_MODEL_2d21f49b9fb74695ba9725a094f8358b"
            ]
          }
        },
        "f4bf7dccdb5547c5a26494b129714d6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1b82306141c4f3c943cc4eed66bf208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_768368e3245c4a0084821e3daa36ac5b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5caf1396793c4f37b4b536169c948fe3"
          }
        },
        "2d21f49b9fb74695ba9725a094f8358b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a183baf314fc4d609dcddad0be537237",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:01&lt;00:00, 18.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df8f968916ab46938f1da16905d90340"
          }
        },
        "768368e3245c4a0084821e3daa36ac5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5caf1396793c4f37b4b536169c948fe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a183baf314fc4d609dcddad0be537237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df8f968916ab46938f1da16905d90340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92ee4c2bd3044409881547711dc3ff3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f80dc1898b2c4313a22ccb763d7a16bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_586cc7ba44dd46e38a7cfcd25ee7419f",
              "IPY_MODEL_9af38d79eb5044bb8601433cd3d5dbc9"
            ]
          }
        },
        "f80dc1898b2c4313a22ccb763d7a16bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "586cc7ba44dd46e38a7cfcd25ee7419f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b8c29edbfdcb48fc8a5c835428217307",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 818,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 818,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_541338b7f10f4c9bbaeb3f75e8548c8e"
          }
        },
        "9af38d79eb5044bb8601433cd3d5dbc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a2d71254ed943338b5b38943b4730fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 818/818 [00:02&lt;00:00, 347B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56b1107dd0654597a44c3c001b8fff2d"
          }
        },
        "b8c29edbfdcb48fc8a5c835428217307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "541338b7f10f4c9bbaeb3f75e8548c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a2d71254ed943338b5b38943b4730fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56b1107dd0654597a44c3c001b8fff2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d242c8c50284ff6a29c17132cd2d831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f267472a0444f8d8c4a32ea2fc0764d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_da39545883764f4391f8fb46fdfb6c39",
              "IPY_MODEL_f3c960345a404e24a2a21e914952d287"
            ]
          }
        },
        "2f267472a0444f8d8c4a32ea2fc0764d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da39545883764f4391f8fb46fdfb6c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ef847f4d1ed44548aa3be126c89c100a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 71,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 71,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_736084b2c7b94e379f2c5b4ddbab3be5"
          }
        },
        "f3c960345a404e24a2a21e914952d287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb8588ab0e614f25a46975d439d624bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 71.0/71.0 [00:00&lt;00:00, 85.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9d61c78db604f2c84878fb5f434d3a1"
          }
        },
        "ef847f4d1ed44548aa3be126c89c100a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "736084b2c7b94e379f2c5b4ddbab3be5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb8588ab0e614f25a46975d439d624bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9d61c78db604f2c84878fb5f434d3a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aec8352918214fbabcbc790df9ca44d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2be6f15f91244f0a83d8cb23ce74b48b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b39b4aa83d9b4ec29a3dd7a58fbeee10",
              "IPY_MODEL_959a24989de64c21bf6bc5e2859d94a6"
            ]
          }
        },
        "2be6f15f91244f0a83d8cb23ce74b48b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b39b4aa83d9b4ec29a3dd7a58fbeee10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_78e9005b2c054030a1da6a62facfc8cb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501013463,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501013463,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_965e59c7720743caaf9b42b6fd9da46a"
          }
        },
        "959a24989de64c21bf6bc5e2859d94a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_24ab7e56486f4ff3b68b04638a7e7610",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:24&lt;00:00, 20.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46f613e8310646f3a8ab5f300f6fd196"
          }
        },
        "78e9005b2c054030a1da6a62facfc8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "965e59c7720743caaf9b42b6fd9da46a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24ab7e56486f4ff3b68b04638a7e7610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46f613e8310646f3a8ab5f300f6fd196": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gi8dnlk4E3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe50f92-8279-4bc3-bfbd-15941a8d0753"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI2JxyBvGto1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba703b3b-9a4c-4cda-9201-bb6d5d93270c"
      },
      "source": [
        "## using code from https://github.com/tim-learn/SHOT\n",
        "## & https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=DEfSbAA4QHas\n",
        "## & https://github.com/youngryan1993/SFDA-Domain-Adaptation-without-Source-Data\n",
        "# !pip3 install -r 'drive/My Drive/source-free-domain-adaptation/baselines/negation/requirements.txt'\n",
        "!pip3 install torchviz\n",
        "!pip3 install transformers==3.02"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 10kB 24.1MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                | 20kB 11.1MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 30kB 8.5MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 40kB 7.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.7.0+cu101)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.16.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3522 sha256=4d6fbf8106063a5992068558b87488a3d9879f16f5643f5ac36c433e2897c297\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n",
            "Collecting transformers==3.02\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/f4/9f93f06dd2c57c7cd7aa515ffbf9fcfd8a084b92285732289f4a5696dd91/transformers-3.2.0-py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (20.7)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 12.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 27.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 54.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.02) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.02) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.02) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.02) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.02) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.02) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.02) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.02) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.02) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=945b4966665a7da48c109c12e4ae5661b314dccd280eae86805422b4b05f13a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.8.1rc2 transformers-3.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7azDws-7Qus"
      },
      "source": [
        "from tabulate import tabulate\n",
        "import logging\n",
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from transformers.data.processors.utils import InputExample, InputFeatures\n",
        "from transformers.data.processors.glue import glue_convert_examples_to_features\n",
        "from transformers.data.processors.utils import DataProcessor\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "\n",
        "labels = [\"-1\", \"1\"]\n",
        "max_length = 128\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akyyfQDE7cg3"
      },
      "source": [
        "import argparse\n",
        "import os, sys\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import random, pdb, math, copy\n",
        "from tqdm import tqdm\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZta4KFeR0Ne"
      },
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn.functional as F\n",
        "def seed_everything(seed=3000):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    import os\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "seed_everything()\n",
        "train_min_step = 1000\n",
        "train_lr=0.0001\n",
        "train_weight_decay = 0.0005\n",
        "train_momentum = 0.9\n",
        "train_update_freq = 50\n",
        "# for step, batch in enumerate(train_dataloader):\n",
        "#   print(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8bj6Zm57VP8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355,
          "referenced_widgets": [
            "d4c00cdedd8745ac97977aeb141af97e",
            "b98670561ff84dd7a041b27bb612919f",
            "b71a6a876d5e45da9a93c5f2dbdd7207",
            "2572dbd5395a4bb6a5f0d797e3ab2a44",
            "b3e9cffa3dba4612945307e7c844ae46",
            "a3fdf569edbc45e1bac28f8e93b6061d",
            "978902007d224b2aa8f1e284ac07edc7",
            "52c7fdbd3e2c410a9bdc606944627eb5",
            "10a29cdb590b405591c13548991610ff",
            "267611b7ac7f485081c15079c2f71538",
            "2de6ad602dfa4fc19d4c1062dab6d2fa",
            "25b6f3d4dbb54b8d970680f9116a4d06",
            "dc3aefa9ef894c288a90109aae5c5ace",
            "f15293da54b74c9a800745730ebadea7",
            "1db1c8e6da5a4a1a9ec9795172445e37",
            "4d6d86c6b4574d2e9b1578cbcdd1a899",
            "ae83ef14db0842e8a725fe6840bcb0ec",
            "0cff9c073fbf491bb265674d1c1bbab8",
            "51ca5bd65ca64e9f8f2194df5cc555f2",
            "c854d1511d734feb9bc4cd34205e1c55",
            "c54a1ee38acd43c99d109f6c23248260",
            "2f1f442a8ebf4229a7769f59d1b3dca3",
            "142b4991d97f4ce0a79a4c202e5bd6fe",
            "77969fa047ec4e078d33764f839e3022",
            "e3c96774e1c34fb0b284b730d49b370c",
            "f4bf7dccdb5547c5a26494b129714d6f",
            "e1b82306141c4f3c943cc4eed66bf208",
            "2d21f49b9fb74695ba9725a094f8358b",
            "768368e3245c4a0084821e3daa36ac5b",
            "5caf1396793c4f37b4b536169c948fe3",
            "a183baf314fc4d609dcddad0be537237",
            "df8f968916ab46938f1da16905d90340",
            "92ee4c2bd3044409881547711dc3ff3a",
            "f80dc1898b2c4313a22ccb763d7a16bf",
            "586cc7ba44dd46e38a7cfcd25ee7419f",
            "9af38d79eb5044bb8601433cd3d5dbc9",
            "b8c29edbfdcb48fc8a5c835428217307",
            "541338b7f10f4c9bbaeb3f75e8548c8e",
            "1a2d71254ed943338b5b38943b4730fd",
            "56b1107dd0654597a44c3c001b8fff2d",
            "2d242c8c50284ff6a29c17132cd2d831",
            "2f267472a0444f8d8c4a32ea2fc0764d",
            "da39545883764f4391f8fb46fdfb6c39",
            "f3c960345a404e24a2a21e914952d287",
            "ef847f4d1ed44548aa3be126c89c100a",
            "736084b2c7b94e379f2c5b4ddbab3be5",
            "cb8588ab0e614f25a46975d439d624bc",
            "b9d61c78db604f2c84878fb5f434d3a1",
            "aec8352918214fbabcbc790df9ca44d4",
            "2be6f15f91244f0a83d8cb23ce74b48b",
            "b39b4aa83d9b4ec29a3dd7a58fbeee10",
            "959a24989de64c21bf6bc5e2859d94a6",
            "78e9005b2c054030a1da6a62facfc8cb",
            "965e59c7720743caaf9b42b6fd9da46a",
            "24ab7e56486f4ff3b68b04638a7e7610",
            "46f613e8310646f3a8ab5f300f6fd196"
          ]
        },
        "outputId": "bb2f5d88-50b3-4669-ae3f-930f3e34f8fb"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "model_name = \"tmills/roberta_sfda_sharpseed\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(model_name,output_hidden_states=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          config=config)\n",
        "\n",
        "fixed_source_net = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
        "                                                            config=config)\n",
        "fixed_source_net.cuda()\n",
        "for k,v in fixed_source_net.named_parameters():\n",
        "  v.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4c00cdedd8745ac97977aeb141af97e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=563.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10a29cdb590b405591c13548991610ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae83ef14db0842e8a725fe6840bcb0ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3c96774e1c34fb0b284b730d49b370c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92ee4c2bd3044409881547711dc3ff3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=818.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d242c8c50284ff6a29c17132cd2d831",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=71.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aec8352918214fbabcbc790df9ca44d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501013463.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2RN47Cz_ngW"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def text_augmentation(lines,y_true_,extra_size_ratio=5):\n",
        "  lt = 6\n",
        "  rt = 3\n",
        "  y_true_= y_true_.unsqueeze(1)\n",
        "  p = re.compile('<e>.*</e>')\n",
        "  concept_terms = []\n",
        "  for line in lines:\n",
        "    line=line[0]\n",
        "    concept_terms.append(re.findall('<e>.*</e>', line)[0])\n",
        "  sz = len(lines)\n",
        "  for i in range(int(extra_size_ratio*sz)):\n",
        "    idx = random.choice(range(sz))\n",
        "    line = lines[idx][0]\n",
        "    n=len(line)\n",
        "    ## taking only a part of sentence that contains the marked term with max 6 words on left and 3 word on right\n",
        "    m=p.search(line)\n",
        "    (start,end) = m.span()\n",
        "\n",
        "    # left = line[:start]\n",
        "    # left_words = left.split()\n",
        "    # left_words = left_words[-min(lt,len(left_words)):]\n",
        "    # left = ' '.join(left_words)\n",
        "\n",
        "    # right = line[end:]\n",
        "    # right_words = right.split()\n",
        "    # right_words = right_words[:min(rt,len(right_words))]\n",
        "    # right = ' '.join(right_words)\n",
        "\n",
        "    # new_line = left+\" \"+m.group()+\" \"+right\n",
        "    # lines.append([new_line])\n",
        "    ## --------\n",
        "    ## replacing concept term with some other concept term\n",
        "    idx2 = random.choice(range(len(concept_terms)))\n",
        "    new_line2 = line[:start] + concept_terms[idx2] + line[end:]\n",
        "    lines.append([new_line2])\n",
        "    # lines.append([line])\n",
        "    # print(torch.tensor([y_true_[idx].cpu().numpy()]))\n",
        "    y_true_ = torch.vstack((y_true_,torch.tensor(y_true_[idx].cpu().numpy()).cuda()))\n",
        "    ## -------\n",
        "    # print(\"original line : \",line)\n",
        "    # print(\"new first line : \",new_line)\n",
        "    # print(\"new second line : \",new_line2)\n",
        "  y_true_ = y_true_.squeeze(1)\n",
        "  return lines,y_true_\n",
        "\n",
        "class NegationDataset(Dataset):\n",
        "    def __init__(self, features):\n",
        "        self.features = features\n",
        "        self.label_list = [\"-1\", \"1\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, i) -> InputFeatures:\n",
        "        return self.features[i]\n",
        "\n",
        "    def get_labels(self):\n",
        "        return self.label_list\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def from_tsv(cls, tsv_file, tokenizer,flag=0,idx = [],y_true_ = [],extra_ratio=0):\n",
        "        \"\"\"Creates examples for the test set.\"\"\"\n",
        "        lines = DataProcessor._read_tsv(tsv_file)\n",
        "        # print(lines)\n",
        "        pos_lines = []\n",
        "        neg_lines = []\n",
        "        extra_lines  = 0\n",
        "        pos_n = 0\n",
        "        neg_n = 0\n",
        "        if idx!=[]:\n",
        "          lines = [line for (i,line) in enumerate(lines) if i in idx]\n",
        "          pos_lines = [line for (i,line) in enumerate(lines) if y_true_[i]==1]\n",
        "          neg_lines = [line for (i,line) in enumerate(lines) if y_true_[i]==0]\n",
        "          pos_n = len(pos_lines)\n",
        "          neg_n = len(neg_lines)\n",
        "          extra_pos_ratio = ((len(neg_lines)/len(pos_lines))*(1+extra_ratio)-1)\n",
        "          extra_neg_ratio = extra_ratio\n",
        "          # print(extra_pos_ratio)\n",
        "\n",
        "        # print(lines)\n",
        "        if flag==1:\n",
        "          pos_y_true_ = torch.ones(pos_n).cuda()\n",
        "          neg_y_true_ = torch.zeros(neg_n).cuda()\n",
        "          pos_lines,pos_y_true_ = text_augmentation(pos_lines,pos_y_true_,extra_pos_ratio)\n",
        "          neg_lines,_ = text_augmentation(neg_lines,neg_y_true_,extra_neg_ratio)\n",
        "          lines = []\n",
        "          # print(len(pos_y_true_))\n",
        "          y_true_ = pos_y_true_.unsqueeze(1)\n",
        "          for line in pos_lines:\n",
        "            lines.append(line)\n",
        "          for line in neg_lines:\n",
        "            lines.append(line)\n",
        "            y_true_ = torch.vstack((y_true_,torch.tensor(0).cuda()))\n",
        "          \n",
        "          y_true_ = y_true_.squeeze(1)\n",
        "            \n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            # if idx==None or i in idx:\n",
        "            guid = 'instance-%d' % i\n",
        "            if line[0] in labels:\n",
        "                text_a = '\\t'.join(line[1:])\n",
        "            else:\n",
        "                text_a = '\\t'.join(line)\n",
        "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=None))\n",
        "\n",
        "        features = glue_convert_examples_to_features(\n",
        "            examples,\n",
        "            tokenizer,\n",
        "            max_length=max_length,\n",
        "            label_list=labels,\n",
        "            output_mode='classification',\n",
        "        )\n",
        "        return cls(features),y_true_\n",
        "train_dataset,_ = NegationDataset.from_tsv('drive/My Drive/source-free-domain-adaptation/practice_text/negation/train.tsv', tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR_pxbklIAZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d37a57b-5049-450a-b2c8-d5eebebf56cd"
      },
      "source": [
        "\n",
        "\n",
        "## preprocesses inputs from the text that can be directly fed to model\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "output_label = []\n",
        "y_true = torch.tensor([]).cuda()\n",
        "entropyl = torch.tensor([]).cuda()\n",
        "m=torch.nn.Softmax(dim=1)\n",
        "cnt=0\n",
        "for feat in train_dataset.features:\n",
        "  input_ids.append(feat.input_ids)\n",
        "  attention_masks.append(feat.attention_mask)\n",
        "  out = fixed_source_net(torch.tensor([feat.input_ids]).cuda(),torch.tensor([feat.attention_mask]).cuda())\n",
        "\n",
        "  pred = m(out[0])\n",
        "  # print(pred)\n",
        "  entropy = torch.sum(- pred * torch.log(pred), dim=1, keepdim=True)\n",
        "  entropy_norm = entropy / np.log(pred.size(1))\n",
        "  entropy_norm = entropy_norm.squeeze(1)\n",
        "  # print(entropy_norm)\n",
        "  entropyl = torch.cat((entropyl,entropy_norm),0)\n",
        "  z = torch.argmax(out[0],dim=1)\n",
        "  z = z.type(torch.cuda.LongTensor)\n",
        "  y_true = torch.cat((y_true,z),0)\n",
        "  # print(y_true)\n",
        "\n",
        "print(entropyl)\n",
        "input_ids = torch.tensor(input_ids)\n",
        "attention_masks = torch.tensor(attention_masks)\n",
        "# pos_id = input_ids[y_true==1]\n",
        "# pos_mask = attention_masks[y_true==1]\n",
        "# neg_id = input_ids[y_true==0]\n",
        "# neg_mask = attention_masks[y_true==0]\n",
        "# pos_size = pos_id.shape[0]\n",
        "# negn = range(neg_id.shape[0])\n",
        "# idx = random.choices(negn,k=pos_size)\n",
        "# neg_red_id = neg_id[idx]\n",
        "# neg_red_mask = neg_mask[idx]\n",
        "# input_red_ids = torch.cat((pos_id,neg_red_id),0)\n",
        "\n",
        "# attention_red_mask = torch.cat((pos_mask,neg_red_mask),0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0259, 0.0041, 0.0039,  ..., 0.0041, 0.1138, 0.0042], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "I2SZsYR7yU6T",
        "outputId": "db4f0f3f-6a31-43d8-8e65-ebc360f89f58"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "pos = (y_true==1)\n",
        "neg = (y_true==0)\n",
        "entropyl_ = entropyl*np.log(2) \n",
        "entropyl_pos = entropyl_[pos]\n",
        "entropyl_neg = entropyl_[neg]\n",
        "entropys = np.linspace(0, math.log(2), 5000)\n",
        "y1 = [len(entropyl_pos[entropyl_pos<x]) for x in entropys]\n",
        "y2 = [len(entropyl_neg[entropyl_neg<x]) for x in entropys]\n",
        "print(y1)\n",
        "print(y2)\n",
        "plt.plot(entropys,y1,label='class 1')\n",
        "plt.plot(entropys,y2,label = 'class 0')\n",
        "plt.xlabel('Self-Entropy threshold')\n",
        "plt.ylabel('No. of sample less than entropy threshold')\n",
        "plt.legend(framealpha=1, frameon=True);\n",
        "plt.savefig('entropy.jpg')\n",
        "plt.show(1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 43, 92, 163, 240, 301, 350, 377, 398, 411, 432, 442, 450, 455, 462, 471, 476, 481, 484, 486, 494, 498, 499, 503, 507, 510, 513, 515, 516, 518, 519, 521, 524, 526, 528, 532, 536, 536, 540, 542, 543, 544, 546, 547, 548, 550, 550, 552, 554, 556, 558, 559, 563, 565, 566, 569, 569, 570, 571, 572, 573, 574, 575, 576, 576, 576, 576, 576, 576, 577, 579, 579, 581, 582, 583, 584, 585, 585, 585, 585, 585, 587, 587, 587, 588, 589, 591, 591, 593, 593, 594, 594, 594, 596, 596, 596, 596, 597, 597, 597, 597, 597, 597, 598, 598, 598, 598, 598, 598, 598, 598, 598, 598, 598, 598, 598, 599, 599, 599, 599, 600, 600, 600, 603, 603, 603, 603, 603, 603, 603, 603, 603, 603, 603, 603, 603, 603, 603, 603, 603, 603, 603, 603, 603, 604, 604, 605, 605, 605, 605, 605, 605, 605, 605, 605, 605, 605, 605, 605, 605, 605, 605, 605, 605, 605, 605, 605, 605, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 606, 607, 608, 608, 608, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 609, 610, 611, 611, 611, 611, 611, 611, 611, 611, 611, 612, 613, 613, 613, 613, 613, 613, 613, 613, 613, 613, 613, 613, 613, 613, 613, 613, 613, 613, 613, 613, 613, 614, 614, 614, 614, 614, 614, 614, 614, 614, 614, 614, 614, 615, 615, 615, 615, 615, 615, 615, 615, 615, 615, 615, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 616, 617, 617, 617, 617, 617, 617, 617, 617, 617, 617, 617, 617, 617, 617, 617, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 618, 619, 619, 619, 619, 619, 619, 619, 619, 619, 619, 619, 619, 619, 619, 619, 619, 619, 619, 619, 619, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 621, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 622, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 623, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 624, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 625, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 626, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 627, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 628, 629, 629, 629, 629, 629, 629, 629, 629, 629, 629, 629, 629, 630, 630, 630, 630, 630, 630, 630, 630, 631, 631, 631, 631, 631, 631, 631, 631, 631, 631, 631, 631, 631, 631, 631, 631, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 632, 633, 633, 633, 633, 634, 634, 634, 634, 634, 634, 634, 634, 634, 634, 634, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 635, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 636, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 637, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 638, 639, 639, 639, 639, 639, 639, 639, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 640, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 641, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 642, 643, 643, 643, 643, 643, 643, 643, 643, 643, 643, 643, 643, 643, 643, 643, 643, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 644, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 646, 647, 647, 647, 647, 647, 647, 647, 647, 647, 647, 647, 647, 647, 647, 647, 647, 647, 647, 647, 647, 647, 647, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 648, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 649, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 651, 652, 652, 652, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 653, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 654, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 655, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 656, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 657, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 658, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 659, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 660, 661, 661, 661, 661, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 662, 663, 663, 663, 663, 663, 663, 663, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 664, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665, 665]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1302, 1675, 1772, 1824, 1856, 1886, 1904, 1912, 1921, 1926, 1932, 1935, 1937, 1944, 1947, 1950, 1950, 1955, 1956, 1958, 1963, 1964, 1966, 1970, 1972, 1974, 1978, 1980, 1981, 1982, 1983, 1987, 1988, 1991, 1994, 1994, 1995, 2001, 2004, 2004, 2008, 2009, 2009, 2010, 2011, 2013, 2014, 2014, 2015, 2015, 2016, 2018, 2020, 2020, 2021, 2021, 2021, 2023, 2025, 2025, 2025, 2026, 2028, 2030, 2030, 2030, 2031, 2031, 2032, 2032, 2032, 2032, 2033, 2033, 2033, 2034, 2034, 2035, 2035, 2035, 2036, 2036, 2036, 2036, 2037, 2038, 2038, 2038, 2038, 2038, 2039, 2039, 2039, 2039, 2040, 2040, 2041, 2043, 2043, 2045, 2045, 2046, 2047, 2047, 2049, 2049, 2050, 2050, 2050, 2050, 2051, 2054, 2055, 2056, 2056, 2057, 2057, 2059, 2059, 2059, 2059, 2059, 2059, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2065, 2065, 2065, 2065, 2065, 2065, 2065, 2066, 2067, 2067, 2068, 2068, 2068, 2068, 2069, 2069, 2070, 2071, 2071, 2071, 2072, 2072, 2073, 2075, 2077, 2077, 2078, 2078, 2078, 2079, 2079, 2079, 2079, 2079, 2079, 2079, 2079, 2079, 2080, 2080, 2080, 2081, 2082, 2082, 2082, 2082, 2083, 2083, 2083, 2083, 2083, 2084, 2084, 2084, 2084, 2084, 2084, 2085, 2086, 2086, 2086, 2086, 2086, 2087, 2087, 2087, 2088, 2088, 2088, 2088, 2089, 2089, 2089, 2089, 2090, 2090, 2090, 2090, 2090, 2090, 2090, 2090, 2090, 2090, 2091, 2091, 2091, 2091, 2091, 2091, 2091, 2091, 2091, 2091, 2091, 2091, 2092, 2092, 2092, 2092, 2092, 2092, 2093, 2093, 2093, 2093, 2094, 2094, 2094, 2094, 2094, 2094, 2094, 2094, 2095, 2096, 2096, 2096, 2096, 2096, 2096, 2096, 2096, 2097, 2098, 2098, 2098, 2098, 2098, 2099, 2099, 2099, 2099, 2099, 2099, 2099, 2099, 2099, 2100, 2100, 2100, 2100, 2102, 2103, 2103, 2103, 2103, 2103, 2103, 2103, 2103, 2104, 2104, 2104, 2105, 2105, 2105, 2105, 2106, 2106, 2106, 2106, 2106, 2107, 2107, 2107, 2108, 2108, 2108, 2108, 2108, 2108, 2108, 2108, 2108, 2108, 2108, 2109, 2109, 2109, 2109, 2109, 2109, 2109, 2109, 2110, 2110, 2110, 2110, 2110, 2110, 2110, 2110, 2110, 2110, 2110, 2111, 2111, 2111, 2111, 2112, 2112, 2112, 2112, 2112, 2112, 2112, 2114, 2115, 2115, 2115, 2115, 2116, 2116, 2116, 2117, 2117, 2117, 2117, 2117, 2117, 2117, 2117, 2117, 2118, 2118, 2119, 2120, 2121, 2121, 2121, 2121, 2121, 2121, 2121, 2121, 2121, 2121, 2121, 2122, 2122, 2122, 2122, 2122, 2122, 2122, 2122, 2122, 2122, 2123, 2123, 2123, 2123, 2123, 2123, 2123, 2123, 2123, 2123, 2123, 2123, 2123, 2123, 2124, 2125, 2125, 2126, 2126, 2127, 2127, 2127, 2127, 2127, 2127, 2127, 2128, 2128, 2128, 2129, 2129, 2129, 2129, 2129, 2130, 2130, 2130, 2130, 2130, 2130, 2130, 2130, 2131, 2131, 2131, 2131, 2131, 2131, 2131, 2131, 2131, 2131, 2131, 2131, 2131, 2131, 2131, 2131, 2131, 2131, 2131, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2132, 2133, 2133, 2133, 2133, 2133, 2133, 2133, 2133, 2133, 2133, 2133, 2133, 2133, 2134, 2134, 2134, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2135, 2136, 2136, 2136, 2136, 2136, 2136, 2136, 2136, 2136, 2136, 2136, 2136, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2137, 2138, 2138, 2138, 2138, 2138, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2139, 2140, 2140, 2140, 2141, 2141, 2141, 2141, 2141, 2141, 2143, 2143, 2143, 2143, 2143, 2143, 2143, 2143, 2144, 2144, 2144, 2144, 2144, 2144, 2145, 2145, 2145, 2145, 2145, 2145, 2145, 2145, 2145, 2145, 2145, 2146, 2146, 2146, 2146, 2146, 2146, 2146, 2146, 2146, 2146, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2147, 2148, 2149, 2150, 2150, 2150, 2150, 2150, 2150, 2150, 2150, 2150, 2150, 2150, 2150, 2150, 2150, 2150, 2150, 2150, 2151, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2152, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2153, 2155, 2157, 2157, 2157, 2157, 2157, 2157, 2157, 2157, 2157, 2158, 2158, 2158, 2158, 2158, 2158, 2158, 2158, 2158, 2158, 2159, 2159, 2159, 2160, 2160, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2161, 2162, 2162, 2162, 2162, 2162, 2162, 2162, 2162, 2162, 2162, 2163, 2163, 2163, 2163, 2163, 2163, 2163, 2163, 2163, 2163, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2164, 2165, 2165, 2165, 2165, 2165, 2165, 2165, 2165, 2165, 2165, 2165, 2165, 2165, 2165, 2165, 2165, 2165, 2165, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2166, 2167, 2167, 2168, 2168, 2168, 2168, 2168, 2168, 2168, 2168, 2168, 2168, 2168, 2168, 2168, 2168, 2168, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2169, 2170, 2170, 2170, 2170, 2170, 2170, 2171, 2171, 2171, 2171, 2171, 2171, 2171, 2171, 2171, 2171, 2171, 2171, 2172, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2173, 2174, 2174, 2174, 2174, 2175, 2175, 2175, 2175, 2175, 2175, 2175, 2175, 2175, 2175, 2175, 2175, 2175, 2175, 2175, 2175, 2175, 2176, 2176, 2176, 2176, 2176, 2176, 2176, 2176, 2176, 2176, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2177, 2178, 2178, 2178, 2178, 2178, 2178, 2178, 2178, 2178, 2178, 2178, 2178, 2178, 2178, 2178, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2179, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2180, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2181, 2182, 2182, 2182, 2182, 2182, 2182, 2182, 2182, 2182, 2182, 2182, 2182, 2182, 2182, 2182, 2182, 2183, 2183, 2183, 2183, 2183, 2184, 2184, 2184, 2184, 2184, 2184, 2184, 2184, 2184, 2184, 2184, 2184, 2184, 2184, 2184, 2184, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2185, 2186, 2186, 2186, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2187, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2188, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2189, 2190, 2190, 2190, 2190, 2190, 2190, 2190, 2190, 2190, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2191, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2192, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2193, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2194, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2195, 2196, 2196, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2197, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2198, 2199, 2199, 2199, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2200, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2201, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2202, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2203, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2204, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2205, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2206, 2207, 2207, 2207, 2207, 2207, 2207, 2207, 2207, 2207, 2207, 2207, 2207, 2207, 2207, 2207, 2207, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2208, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2209, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2210, 2211, 2211, 2211, 2211, 2211, 2211, 2211, 2211, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2212, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2213, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2214, 2215, 2215, 2215, 2215, 2215, 2215, 2215, 2215, 2215, 2215, 2215, 2215, 2215, 2215, 2215, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2216, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2217, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2218, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2219, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2220, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221, 2221]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_CMNPhzpRH-",
        "outputId": "4f3c2544-7de7-4fa9-d499-71325093487a"
      },
      "source": [
        "import numpy as np\n",
        "l = np.array([0.8588,0.8501,.8526,0.8541])\n",
        "l1 = np.array([0.903,0.8718,0.873,0.877])\n",
        "l2 = np.array([0.818,0.829,0.833,0.8322])\n",
        "np.mean(l2),np.std(l2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.82805, 0.005992286708761543)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmXd3pN91mr3",
        "outputId": "2f057ec1-8ef3-4446-ae62-3aa1d59abb4d"
      },
      "source": [
        "# entropyl_sorted = torch.sort(entropyl)\n",
        "# torch.std(entropyl_sorted.values)\n",
        "# torch.quantile(entropyl_sorted.values,torch.tensor([0.25,0.33,0.5,0.67,0.75]).cuda())\n",
        "# pos_entropy_max = torch.sort(entropyl[y_true==1]).values[499]\n",
        "# neg_entropy_max = torch.sort(entropyl[y_true==0]).values[499]\n",
        "pos_entropyl = torch.sort(entropyl[y_true==1])\n",
        "neg_entropyl = torch.sort(entropyl[y_true==0])\n",
        "pos_threshold = torch.quantile(pos_entropyl.values,torch.tensor([0.5]).cuda())\n",
        "neg_threshold = torch.quantile(neg_entropyl.values,torch.tensor([0.5]).cuda())\n",
        "# pos_half_entropy = \n",
        "# mask = (entropyl<=0.113)\n",
        "# idx = torch.where(mask==True)[0]\n",
        "# # print(len(idx))\n",
        "print(pos_threshold)\n",
        "pos_mask = (y_true==1) & (entropyl<=pos_threshold)\n",
        "print(len(input_ids[pos_mask]))\n",
        "neg_mask = (y_true==0) & (entropyl<pos_threshold)\n",
        "print(len(input_ids[neg_mask]))\n",
        "\n",
        "\n",
        "mask = (((entropyl<pos_threshold) & (y_true==1)) | ((entropyl<pos_threshold) & (y_true==0)))\n",
        "idx = torch.where(mask==True)[0]\n",
        "# new_train_dataset = NegationDataset.from_tsv('drive/My Drive/source-free-domain-adaptation/practice_text/negation/train.tsv', tokenizer,1,idx.tolist())\n",
        "y_true_ = y_true[idx]\n",
        "new_train_dataset,y_true_= NegationDataset.from_tsv('drive/My Drive/source-free-domain-adaptation/practice_text/negation/train.tsv', tokenizer,1,idx.tolist(),y_true_,3)\n",
        "# print(len(y_true_[y_true_==1]),len(y_true_[y_true_==0]))\n",
        "# idx = \n",
        "# entropyl_sorted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1129], device='cuda:0')\n",
            "333\n",
            "2137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13tIuvvSLXon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efff827a-9010-4dab-90f1-2c861692e24b"
      },
      "source": [
        "# len(y_true_)\n",
        "print(len(y_true_[y_true_==0]))\n",
        "print(len(y_true_[y_true_==1]))\n",
        "print(len(new_train_dataset.features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8548\n",
            "8548\n",
            "17096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOXTHZXHHuD3",
        "outputId": "8c0c1280-0f84-4a94-abc1-5813f614f64f"
      },
      "source": [
        "0.1/math.log(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14426950408889636"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS-aVf9jDWFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66361f4-1af6-4f62-c477-56730997e85c"
      },
      "source": [
        "new_input_ids = []\n",
        "new_attention_masks = []\n",
        "\n",
        "for feat in new_train_dataset.features:\n",
        "  new_input_ids.append(feat.input_ids)\n",
        "  new_attention_masks.append(feat.attention_mask)\n",
        "\n",
        "new_input_ids = torch.tensor(new_input_ids)\n",
        "new_attention_masks = torch.tensor(new_attention_masks)\n",
        "y_true_ = torch.tensor(y_true_)\n",
        "y_true_ = y_true_.type(torch.cuda.LongTensor)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_crBYnQgOucr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c461bdad-c77b-41bd-91dc-ddf5d67c24ba"
      },
      "source": [
        " \n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        " \n",
        "dataset = TensorDataset(new_input_ids, new_attention_masks,y_true_)\n",
        "# dataset = TensorDataset(input_red_ids,attention_red_mask)\n",
        "# dataset.tensors\n",
        "batch_size=16 # 32\n",
        "train_dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            # sampler = RandomSampler(dataset), # Select batches randomly        ### was commented for 0.8759\n",
        "            shuffle = True,  ### not here for 0.8759\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "APM_dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size = 16 # T\n",
        ")\n",
        "print(len(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt1dJEsI0scc"
      },
      "source": [
        "\n",
        "def proto_augmentation(prototype_memory,prototype_memory_dict,num_prototype_,lb = 0.5,extra_size_ratio = 0.5):\n",
        "  prototype_memory = []\n",
        "  for cls in range(2):\n",
        "    extra_prototype = np.empty((0,768), np.float32)\n",
        "    l = prototype_memory_dict[cls]\n",
        "    \n",
        "    for i in range(int(extra_size_ratio*num_prototype_)):\n",
        "      idx=random.sample(range(num_prototype_),2)\n",
        "      new_prototype = (l[idx[1]]-l[idx[0]])*lb+l[idx[0]]\n",
        "      extra_prototype = np.append(extra_prototype,np.array([new_prototype]),axis=0)\n",
        "    prototype_memory_dict[cls] = np.concatenate((l,extra_prototype),axis = 0)\n",
        "    prototype_memory.append(prototype_memory_dict[cls])\n",
        "  num_prototype_ += int(extra_size_ratio*num_prototype_)\n",
        "  prototype_memory = np.concatenate(prototype_memory,axis=0)\n",
        "\n",
        "  return prototype_memory,prototype_memory_dict,num_prototype_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNwGf52B27HJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e242299c-323f-4b47-80a8-fc49d22144ec"
      },
      "source": [
        "\n",
        "import time\n",
        "print(len(dataset))\n",
        "def APM_ours(target_trainable_net):\n",
        "  target_trainable_net = target_trainable_net.cuda()\n",
        "\n",
        "  cnt=1\n",
        "  available_cls = []\n",
        "  h_dict = {}\n",
        "  feat_dict = {}\n",
        "  missing_cls = []\n",
        "  after_softmax_numpy_for_emergency = []\n",
        "  feature_numpy_for_emergency = []\n",
        "  max_prototype_bound = 100\n",
        "  start_time = time.time()\n",
        "  m=torch.nn.Softmax(dim=1)\n",
        "\n",
        "  for cls in range(2): ## number of classes and their cls\n",
        "    h_dict[cls] = []\n",
        "    feat_dict[cls] = []\n",
        "\n",
        "  for dt in APM_dataloader:\n",
        "    input_id = dt[0].cuda()\n",
        "    attention_mask = dt[1].cuda()\n",
        "\n",
        "    out = target_trainable_net(input_id,attention_mask=attention_mask)\n",
        "    \n",
        "    ### ?\n",
        "    fc1 = out[1][-1][:,0,:]\n",
        "    pred = m(out[0])\n",
        "\n",
        "    after_softmax_numpy_for_emergency.append(pred.cpu().detach().numpy())\n",
        "    feature_numpy_for_emergency.append(fc1.cpu().detach().numpy())\n",
        "    pseudo_label = torch.argmax(pred, dim=1)\n",
        "    pseudo_label = pseudo_label.cpu()\n",
        "    entropy = torch.sum(- pred * torch.log(pred), dim=1, keepdim=True)\n",
        "    entropy_norm = entropy / np.log(pred.size(1))\n",
        "    entropy_norm = entropy_norm.squeeze(1)\n",
        "    entropy_norm = entropy_norm.cpu()\n",
        "    # diff = -torch.abs(out[0][:,0] - out[0][:,1])\n",
        "    for cls in range(2):\n",
        "      # stack H for each class\n",
        "      cls_filter = (pseudo_label == cls)\n",
        "      list_loc = (torch.where(cls_filter == 1))[0]\n",
        "      num_element = list(list_loc.numpy())\n",
        "      if len(list_loc) == 0:\n",
        "          missing_cls.append(cls)\n",
        "          continue\n",
        "      available_cls.append(cls)\n",
        "      filtered_ent = torch.gather(entropy_norm, dim=0, index=list_loc)\n",
        "      filtered_feat = torch.gather(fc1.cpu(), dim=0, index=list_loc.unsqueeze(1).repeat(1, 768))\n",
        "      h_dict[cls].append(filtered_ent.detach().numpy())\n",
        "      feat_dict[cls].append(filtered_feat.cpu().detach().numpy())\n",
        "\n",
        "  available_cls = np.unique(available_cls)\n",
        "  # print(feat_dict[0],h_dict[0])\n",
        "  # print(feat_dict[1],h_dict[1])\n",
        "  prototype_memory = []\n",
        "  prototype_memory_dict = {}\n",
        "  after_softmax_numpy_for_emergency = np.concatenate(after_softmax_numpy_for_emergency, axis=0)\n",
        "  feature_numpy_for_emergency = np.concatenate(feature_numpy_for_emergency, axis=0)\n",
        "  max_top1_ent = 0\n",
        "  for cls in available_cls:\n",
        "    ents_np = np.concatenate(h_dict[cls], axis=0)\n",
        "    ent_idxs = np.argsort(ents_np)\n",
        "    top1_ent = ents_np[ent_idxs[0]]\n",
        "    if max_top1_ent < top1_ent:\n",
        "      max_top1_ent = top1_ent\n",
        "      max_top1_class = cls\n",
        "\n",
        "  class_protypeNum_dict = {}\n",
        "  # max_prototype = 0\n",
        "  max_prototype = 100\n",
        "  # for cls in available_cls:\n",
        "  #   ents_np = np.concatenate(h_dict[cls], axis=0)\n",
        "  #   ents_np_filtered = (ents_np <= max_top1_ent)\n",
        "  #   class_protypeNum_dict[cls] = ents_np_filtered.sum()\n",
        "\n",
        "  #   if max_prototype < ents_np_filtered.sum():\n",
        "  #     max_prototype = ents_np_filtered.sum()\n",
        "\n",
        "  # if max_prototype > max_prototype_bound:\n",
        "  #     max_prototype = max_prototype_bound\n",
        "\n",
        "  # print(feat_dict)\n",
        "  for cls in range(2):\n",
        "\n",
        "    if cls in available_cls:\n",
        "      ents_np = np.concatenate(h_dict[cls], axis=0)\n",
        "      \n",
        "      feats_np = np.concatenate(feat_dict[cls],axis=0)    # print(prototype_memory)xis=0)\n",
        "      # print(feat_dict[cls])\n",
        "      ent_idxs = np.argsort(ents_np)\n",
        "      # print(ent_idxs,class_protypeNum_dict[cls])\n",
        "    \n",
        "      truncated_feat = feats_np[ent_idxs[:100]]\n",
        "      # truncated_feat = feats_np[ent_idxs[:class_protypeNum_dict[cls]]]\n",
        "      fit_to_max_prototype = np.concatenate([truncated_feat] * (int(max_prototype / truncated_feat.shape[0]) + 1),\n",
        "                                            axis=0)\n",
        "      fit_to_max_prototype = fit_to_max_prototype[:max_prototype, :]\n",
        "      prototype_memory.append(fit_to_max_prototype)\n",
        "      prototype_memory_dict[cls] = fit_to_max_prototype\n",
        "    else:\n",
        "      after_softmax_torch_for_emergency = torch.Tensor(after_softmax_numpy_for_emergency)\n",
        "      emergency_idx = torch.argsort(after_softmax_torch_for_emergency, descending=True, dim=1)\n",
        "      cls_emergency_idx = emergency_idx[:, cls]\n",
        "      cls_emergency_idx = cls_emergency_idx[0]\n",
        "      cls_emergency_idx_numpy = cls_emergency_idx.data.numpy()\n",
        "\n",
        "      copied_features_emergency = np.concatenate(\n",
        "          [np.expand_dims(feature_numpy_for_emergency[cls_emergency_idx_numpy], axis=0)] * max_prototype, axis=0)\n",
        "\n",
        "      prototype_memory.append(copied_features_emergency)\n",
        "      prototype_memory_dict[cls] = copied_features_emergency\n",
        "\n",
        "  print(\"** APM update... time:\", time.time() - start_time)\n",
        "  \n",
        "  prototype_memory = np.concatenate(prototype_memory, axis=0) ## check\n",
        "  num_prototype_ = int(max_prototype)\n",
        "  # print(num_prototype_,prototype_memory_dict,prototype_memory)\n",
        "  return prototype_memory, num_prototype_, prototype_memory_dict\n",
        "\n",
        "fixed_source_net.cuda()\n",
        "# prototype_memory, num_prototype_, prototype_memory_dict = APM_ours(fixed_source_net)\n",
        "# prototype_memory,prototype_memory_dict,num_prototype_ = proto_augmentation(prototype_memory,prototype_memory_dict,num_prototype_)\n",
        "\n",
        "def check_if_updated(model1,model2):\n",
        "  a=target_trainable_net.roberta.encoder.layer[10].attention.output.dense.weight\n",
        "  b=fixed_source_net.roberta.encoder.layer[10].attention.output.dense.weight\n",
        "  if np.array_equal(a.cpu().detach().numpy(),b.cpu().detach().numpy()):\n",
        "    print(\"same\")\n",
        "  else:\n",
        "    print(\"different\")\n",
        "\n",
        "# check_if_updated(fixed_source_net,target_trainable_net)\n",
        "# del prototype_memory \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztC5C05nvRnS"
      },
      "source": [
        "import math\n",
        "def op_copy(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr0'] = param_group['lr']\n",
        "    return optimizer\n",
        "\n",
        "def lr_scheduler(optimizer, iter_num, max_iter, gamma=10, power=0.75):\n",
        "    decay = (1 + gamma * iter_num / max_iter) ** (-power)\n",
        "    # decay = 1/math.sqrt(iter_num)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = param_group['lr0'] * decay\n",
        "        param_group['weight_decay'] =0.0005\n",
        "        param_group['momentum'] = 0.9\n",
        "        param_group['nesterov'] = True\n",
        "    return optimizer\n",
        "\n",
        "def tensor_l2normalization(q):\n",
        "    qn = torch.norm(q, p=2, dim=1).detach().unsqueeze(1)\n",
        "    q = q.div(qn.expand_as(q))\n",
        "    return q\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAvKGkOtfPcb"
      },
      "source": [
        "import copy \n",
        "model_name = \"tmills/roberta_sfda_sharpseed\"\n",
        "# del config1,tokenizer1,target_trainable_net\n",
        "config1 = AutoConfig.from_pretrained(model_name,output_hidden_states=True)\n",
        "tokenizer1 = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          config=config1)\n",
        "\n",
        "target_trainable_net = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
        "                                                            config=config1)\n",
        "target_trainable_net = target_trainable_net.cuda()\n",
        "class classifier_head(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      # self.dense = nn.Linear(in_features = 768,out_features = 768,bias=True)\n",
        "      self.dense = copy.deepcopy(target_trainable_net.classifier.dense)\n",
        "      # self.dropout = nn.Dropout(p=0.1, inplace = False)\n",
        "      self.dropout = copy.deepcopy(target_trainable_net.classifier.dropout)\n",
        "      # self.out_proj = nn.Linear(in_features = 768, out_features = 2,bias=True)\n",
        "      self.out_proj = copy.deepcopy(target_trainable_net.classifier.out_proj)\n",
        "  def forward(self, x):\n",
        "      # take <s> token (equiv. to [CLS])\n",
        "      # x = feature[:,0,:]\n",
        "      x = self.dropout(x)\n",
        "      x = self.dense(x)\n",
        "      x = torch.tanh(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.out_proj(x)\n",
        "      return x\n",
        "\n",
        "classifier = classifier_head()\n",
        "classifier = classifier.cuda() ### change"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwUq6HycR8Rc"
      },
      "source": [
        "# for k,v in target_trainable_net.named_parameters():\n",
        "#   a = k.split(\".\")\n",
        "#   if a[0]!=\"classifier\" and a[1] not in [\"embeddings\",\"pooler\"] and int(a[3])<=8:\n",
        "#     v.requires_grad = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1NV5ScldjM1"
      },
      "source": [
        "\n",
        "def load_testdata(file_name):\n",
        "    test_dataset,_ = NegationDataset.from_tsv(file_name, tokenizer)\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for feat in test_dataset.features:\n",
        "        input_ids.append(feat.input_ids)\n",
        "        attention_masks.append(feat.attention_mask)\n",
        "\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "    print(input_ids.shape,attention_masks.shape)\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_masks,torch.arange(input_ids.size(0)))\n",
        "    \n",
        "    # batch_size=32 # 32\n",
        "    test_dataloader = DataLoader(dataset, batch_size = batch_size)\n",
        "    print(batch_size)\n",
        "    return test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxL3qawvDJh-"
      },
      "source": [
        "\n",
        "def predict(test_file,output_test_file,threshold = 0.5):\n",
        "  # target_trainable_net = \n",
        "  # tokenizer =\n",
        "  start=True\n",
        "  test_dataloader = load_testdata(test_file)\n",
        "  for data in test_dataloader:\n",
        "    # out = fixed_source_net(data[0].cuda(),data[1].cuda())\n",
        "    out = target_trainable_net(data[0].cuda(),data[1].cuda())\n",
        "    if start:\n",
        "        predict = out[0].cpu().detach().numpy()\n",
        "        start = False\n",
        "    else:\n",
        "        predict = np.concatenate((predict,out[0].cpu().detach().numpy()))\n",
        "  m=torch.nn.Softmax(dim=1)\n",
        "  p = m(torch.tensor(predict))\n",
        "  p1 = np.ones(p.shape[0],np.int)\n",
        "  for i in range(p.shape[0]):\n",
        "    prob = p[i][1]\n",
        "    if prob>threshold:\n",
        "      p1[i] = 1\n",
        "    else:\n",
        "      p1[i] = -1\n",
        "  # predict = np.argmax(predict,1)\n",
        "  with open(output_test_file, \"w\") as writer:\n",
        "    logger.info(\"***** Test results *****\")\n",
        "    for index, item in enumerate(p1):\n",
        "        writer.write(\"%s\\n\" % p1[index])\n",
        "\n",
        "  return p1\n",
        "\n",
        "# predict('drive/My Drive//source-free-domain-adaptation/practice_text/negation/dev.tsv','drive/My Drive//source-free-domain-adaptation/submission/negation/system.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEVf9unX03xc",
        "outputId": "b3bbdb89-429c-4ac2-cde5-c2db5ec0245c"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('drive/My Drive/proto_aug')\n",
        "target_trainable_net = AutoModelForSequenceClassification.from_pretrained('drive/My Drive/proto_aug').cuda()\n",
        "pred = predict('drive/My Drive//source-free-domain-adaptation/practice_text/negation/dev.tsv','system.tsv')\n",
        "# lines1 = DataProcessor._read_tsv('drive/My Drive/task1_test.tsv')\n",
        "# lines1_ = []\n",
        "# for line in lines1:\n",
        "#   if line[0][0]==\"\\\"\":\n",
        "#     lines1_.append([line[0][1:-1]])\n",
        "#   else:\n",
        "#     lines1_.append([line[0]]) \n",
        "# lines2 = DataProcessor._read_tsv('drive/My Drive//source-free-domain-adaptation/practice_text/negation/dev.tsv')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5545, 128]) torch.Size([5545, 128])\n",
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZbG9DKf9G9k",
        "outputId": "a5d23e53-1a8f-4c7c-a1f0-8fcf0b0adb11"
      },
      "source": [
        "# ids = [idx for idx,line in enumerate(lines2) if line in lines1]\n",
        "# s= set([line[0] for line in lines1_])\n",
        "# print(len(lines1_))\n",
        "# ids = []\n",
        "# s = set([])\n",
        "# for line in lines1_:\n",
        "#   for idx,ln in enumerate(lines2):\n",
        "#     if ln==line:\n",
        "#       ids.append(idx)\n",
        "#       break\n",
        "# print(len(ids))\n",
        "\n",
        "# # for line in lines1:\n",
        "# #   if line not in lines2:\n",
        "# #     print(line)\n",
        "# # residual = [line for line in lines2 if line not in lines1]\n",
        "# test_true = np.loadtxt('drive/My Drive//source-free-domain-adaptation/practice_text/negation/dev_labels.txt',dtype=np.int32)\n",
        "# test_true = test_true[ids]\n",
        "# print(len(test_true[test_true==1]))\n",
        "# print(f1_score(test_true,pred),precision_score(test_true,pred),recall_score(test_true,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2773\n",
            "2773\n",
            "569\n",
            "0.8801498127340824 0.9418837675350702 0.8260105448154658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvYvWCUZHgVl"
      },
      "source": [
        "def read_tsv(file):\n",
        "    output = []\n",
        "    with open(file, 'r') as f_output:\n",
        "        for record in f_output:\n",
        "            output.append(int(record))\n",
        "    return output\n",
        "\n",
        "def score_negation(ref_domain,res_domain):\n",
        "    ref = read_tsv(ref_domain)\n",
        "    res = read_tsv(res_domain)\n",
        "    assert len(ref) == len(res)\n",
        "    trainable_f1_score = f1_score(ref,res)\n",
        "    trainable_prec = precision_score(ref,res)\n",
        "    trainable_recall = recall_score(ref,res)\n",
        "    scores = [['trained',trainable_f1_score,trainable_prec,trainable_recall]]\n",
        "    print(tabulate(scores,headers=['model','f1 score','precision','recall']))\n",
        "    return trainable_f1_score,trainable_prec,trainable_recall\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwwbVmX6dlH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67094a56-342e-49b2-fe57-00675ff4048e"
      },
      "source": [
        "test_dataloader = load_testdata('drive/My Drive//source-free-domain-adaptation/practice_text/negation/dev.tsv')\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score,confusion_matrix\n",
        "\n",
        "\n",
        "squarer = lambda t: 1 if t>1 else 0\n",
        "vfunc = np.vectorize(squarer)\n",
        "def evaluation(test_dataloader,target_net,fixed_source_net,flag=0):\n",
        "    \n",
        " \n",
        "    if flag == 1:\n",
        "      pred1 = np.array([])\n",
        "      for itr in range(3,6):\n",
        "        start=True\n",
        "        target_net = AutoModelForSequenceClassification.from_pretrained('drive/My Drive/models_APM/'+'1_'+str(itr)+'/').cuda()\n",
        "        for data in test_dataloader:\n",
        "            out = target_net(data[0].cuda(),data[1].cuda())\n",
        "            if start:\n",
        "                predict = out[0].cpu().detach().numpy()\n",
        "                start = False\n",
        "            else:\n",
        "                predict = np.concatenate((predict,out[0].cpu().detach().numpy()))\n",
        "        predict = np.argmax(predict,1)\n",
        "        print(predict)\n",
        "        if itr==3:\n",
        "          pred1 = predict\n",
        "        else:\n",
        "          pred1 = np.vstack([pred1,predict])\n",
        "      \n",
        "      predict = pred1.sum(axis=0)\n",
        "      predict = vfunc(predict)\n",
        "      print(predict)\n",
        "    else:\n",
        "      start=True\n",
        "      # target_net = AutoModelForSequenceClassification.from_pretrained('drive/My Drive/models_APM/'+str(itr)+'_3/').cuda()\n",
        "      for data in test_dataloader:\n",
        "          out = target_net(data[0].cuda(),data[1].cuda())\n",
        "          if start:\n",
        "              predict = out[0].cpu().detach().numpy()\n",
        "              start = False\n",
        "          else:\n",
        "              predict = np.concatenate((predict,out[0].cpu().detach().numpy()))\n",
        "      predict = np.argmax(predict,1)\n",
        "    # print(predict.shape)\n",
        "\n",
        "    fixed_source_net = fixed_source_net.cuda()\n",
        "    fixed_source_net.eval()\n",
        "    start=True\n",
        "    for data in test_dataloader:\n",
        "        out1 = fixed_source_net(data[0].cuda(),data[1].cuda())\n",
        "        if start:\n",
        "            predict1 = out1[0].cpu().detach().numpy()\n",
        "            start = False\n",
        "        else:\n",
        "            predict1 = np.concatenate((predict1,out1[0].cpu().detach().numpy()))\n",
        "    predict1 = np.argmax(predict1,1)\n",
        "    # print(predict1.shape)\n",
        " \n",
        "    pred = np.array([0]*5545)\n",
        "    for i in range(5545):\n",
        "        pred[i] = labels[predict[i]]\n",
        "    # print(pred.shape)\n",
        " \n",
        "    pred1 = np.array([0]*5545)\n",
        "    for i in range(5545):\n",
        "        pred1[i] = labels[predict1[i]]\n",
        "    # print(pred1.shape)\n",
        "    \n",
        "    test_true = np.loadtxt('drive/My Drive//source-free-domain-adaptation/practice_text/negation/dev_labels.txt',dtype=np.int32)\n",
        "    # confusion_matrix(test_true,pred1),\n",
        "    # ,confusion_matrix(test_true,pred)\n",
        "    \n",
        "    trainable_f1_score = f1_score(test_true,pred)\n",
        "    trainable_prec = precision_score(test_true,pred)\n",
        "    trainable_recall = recall_score(test_true,pred)\n",
        "    scores = [['pretrained',f1_score(test_true,pred1),precision_score(test_true,pred1),recall_score(test_true,pred1)],\n",
        "              ['trained',trainable_f1_score,trainable_prec,trainable_recall]]\n",
        "    print(tabulate(scores,headers=['model','f1 score','precision','recall']))\n",
        "    print(confusion_matrix(test_true,pred))\n",
        "    print(confusion_matrix(test_true,pred1))\n",
        "    return trainable_f1_score,trainable_prec,trainable_recall\n",
        "  \n",
        "def forward(y_logits, y_true):\n",
        "    beta = 1\n",
        "    epsilon = 1e-15\n",
        "    # print(y_logits)\n",
        "    y_pred = torch.sigmoid(y_logits)\n",
        "    # m=torch.nn.Softmax(dim=1)\n",
        "    # y_pred = m(y_logits)\n",
        "    # print(y_pred)\n",
        "    \n",
        "    TP = (y_pred * y_true).sum(dim=1)\n",
        "    FP = (y_pred * (1-y_true)).sum(dim=1)\n",
        "    FN = ((1-y_pred) *  y_true).sum(dim=1)\n",
        "    fbeta = (1 + beta**2) * TP / ((1 + beta**2) * TP + (beta**2) * FN + FP + epsilon)\n",
        "    fbeta = fbeta.clamp(min=epsilon, max=1 - epsilon)\n",
        "    return 1 - fbeta.mean()\n",
        "\n",
        "# evaluation(test_dataloader,target_trainable_net,fixed_source_net)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5545, 128]) torch.Size([5545, 128])\n",
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpqJ30x9US_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f07a2576-5aa5-47b9-bfc0-06c6d3ba97f9"
      },
      "source": [
        "## training portion of the code\n",
        "from torch.autograd import Variable\n",
        "import copy \n",
        "import math\n",
        "# def target_train(train_lr,train_update_freq):\n",
        "# avg_acc = [0]*11\n",
        "l=[]\n",
        "for itr in range(1):\n",
        "  del target_trainable_net,classifier\n",
        "  target_trainable_net = AutoModelForSequenceClassification.from_pretrained(model_name,config=config1)\n",
        "  target_trainable_net = target_trainable_net.cuda()\n",
        "  classifier = classifier_head()\n",
        "  classifier = classifier.cuda()\n",
        "  for k,v in target_trainable_net.named_parameters():\n",
        "    x = k.split('.')\n",
        "    if x[0]=='classifier':\n",
        "      v.requires_grad=False\n",
        "\n",
        "\n",
        "  train_start_time=time.time()\n",
        "\n",
        "  train_min_step = 3204#2650#1335#2670#930#188*3 ### 1000 originally\n",
        "  train_lr=0.0005\n",
        "  train_weight_decay = 0.0005\n",
        "  train_momentum = 0.9\n",
        "  train_update_freq = 96 #96 # changed from 10\n",
        "\n",
        "  # target_trainable_net.train()\n",
        "  optimizer = optim.SGD(list(filter(lambda p: p.requires_grad, target_trainable_net.parameters()))+list(classifier.parameters()), \n",
        "                        lr=train_lr, weight_decay=train_weight_decay, momentum=train_momentum, nesterov=True)\n",
        "\n",
        "  optimizer = op_copy(optimizer)\n",
        "  global_step = 0\n",
        "  best_acc = 0\n",
        "  best_epoch = 0\n",
        "  epoch_id = 0\n",
        "  class_num =  2\n",
        "  max_epoch = math.ceil((train_min_step*batch_size)/len(dataset))\n",
        "  pt_memory_update_frequncy =  train_update_freq\n",
        "  # eval_interval = 100\n",
        "  cnt=0\n",
        "  m=torch.nn.Softmax(dim=1)\n",
        "\n",
        "  # fixed_source_net.train()\n",
        "  classifier.train()\n",
        "\n",
        "  # fixed_source_net.zero_grad()\n",
        "  classifier.zero_grad()\n",
        "  target_trainable_net.zero_grad()\n",
        "\n",
        "  while global_step < train_min_step:\n",
        "    epoch_id += 1\n",
        "    max_iter = max_epoch * len(train_dataloader)\n",
        "    # print(max_iter)\n",
        "    epoch_start_time=time.time()\n",
        "\n",
        "    for i, dt in enumerate(train_dataloader):\n",
        "      # APM init/update\n",
        "      # if (global_step) % pt_memory_update_frequncy == 0: ### change\n",
        "      #     target_trainable_net.eval() ### change\n",
        "      #     prototype_memory, num_prototype_,prototype_memory_dict = APM_ours(target_trainable_net)\n",
        "          # prototype_memory,prototype_memory_dict,num_prototype_ = proto_augmentation(prototype_memory,prototype_memory_dict,num_prototype_) # Tried augmentation in prototype feature\n",
        "\n",
        "      input_id = dt[0].cuda()\n",
        "      attention_mask = dt[1].cuda()\n",
        "      pseudo_label = dt[2].cuda()\n",
        "      fixed_source_net.train()\n",
        "      out_s = fixed_source_net(input_id,attention_mask=attention_mask)\n",
        "      pseudo_label_s = torch.argmax(out_s[0], dim=1).cuda()\n",
        "      pseudo_label_hot_s = torch.zeros(out_s[0].shape).cuda()\n",
        "      pseudo_label_hot_s = pseudo_label_hot_s.scatter(1,pseudo_label_s.unsqueeze(1),1.0).cuda()\n",
        "      ## trainable target model\n",
        "      target_trainable_net.train()\n",
        "      out_t = target_trainable_net(input_id,attention_mask=attention_mask)\n",
        "      fc_t = out_t[1][-1][:,0,:] #target_trainable_net.roberta.pooler(out_t[1][-1])\n",
        "      feature_embed_tensor = fc_t.cpu()\n",
        "      \n",
        "      \n",
        "      logit_s2t = classifier(fc_t) ### change\n",
        "      logit_t = out_t[0]\n",
        "\n",
        "      \n",
        "      \n",
        "      # proto_feat_tensor = torch.Tensor(prototype_memory)\n",
        "      # proto_feat_tensor = tensor_l2normalization(proto_feat_tensor)\n",
        "      # batch_feat_tensor = tensor_l2normalization(feature_embed_tensor)\n",
        "\n",
        "      # sim_mat = torch.mm(batch_feat_tensor, proto_feat_tensor.permute(1,0))\n",
        "      # sim_mat = F.avg_pool1d(sim_mat.unsqueeze(0), kernel_size=num_prototype_, stride=num_prototype_).squeeze(0)# (B, #class)\n",
        "      \n",
        "\n",
        "      # pseudo_label_t = torch.argmax(sim_mat, dim=1).cuda()\n",
        "      # # pseudo_label_hot_t = torch.zeros(sim_mat.shape).scatter(1,a.unsqueeze(1),1.0).cuda()\n",
        "      # if not np.array_equal(pseudo_label_t.cpu().detach().numpy(),pseudo_label_s.cpu().detach().numpy()):\n",
        "      #   # print(sim_mat,logit_t,pseudo_label_s,pseudo_label_t)\n",
        "      #   cnt=cnt+1\n",
        "      # # lr_scheduler(optimizer, iter_num=global_step, max_iter=max_iter)\n",
        "\n",
        "      # # confidence-based filtering\n",
        "      # arg_idxs = torch.argsort(sim_mat, dim=1, descending=True) # (B, #class)\n",
        "      # first_group_idx = arg_idxs[:, 0]\n",
        "      # second_group_idx = arg_idxs[:, 1]\n",
        "      # first_group_feat = [prototype_memory_dict[int(x.numpy())] for x in first_group_idx]\n",
        "      # first_group_feat_tensor = torch.tensor(np.concatenate(first_group_feat, axis=0)) # (B*P, 2048)\n",
        "      # first_group_feat_tensor = tensor_l2normalization(first_group_feat_tensor)\n",
        "\n",
        "      # second_group_feat = [prototype_memory_dict[int(x.numpy())] for x in second_group_idx]\n",
        "      # second_group_feat_tensor = torch.tensor(np.concatenate(second_group_feat, axis=0)) # (B*P, 2048)\n",
        "      # second_group_feat_tensor = tensor_l2normalization(second_group_feat_tensor)\n",
        "\n",
        "      # feature_embed_tensor_repeat = torch.Tensor(np.repeat(feature_embed_tensor.cpu().detach().numpy(), repeats=num_prototype_, axis=0))\n",
        "      # feature_embed_tensor_repeat = tensor_l2normalization(feature_embed_tensor_repeat)\n",
        "\n",
        "      # first_dist_mat = 1 - torch.mm(first_group_feat_tensor, feature_embed_tensor_repeat.permute(1,0)) # distance = 1  - simialirty\n",
        "      # second_dist_mat = 1 - torch.mm(second_group_feat_tensor, feature_embed_tensor_repeat.permute(1,0))\n",
        "\n",
        "      # first_dist_mat = F.max_pool2d(first_dist_mat.permute(1,0).unsqueeze(0).unsqueeze(0), kernel_size=num_prototype_, stride=num_prototype_).squeeze(0).squeeze(0)# (B, #class)\n",
        "      # second_dist_mat = -1*F.max_pool2d(-1* second_dist_mat.permute(1,0).unsqueeze(0).unsqueeze(0), kernel_size=num_prototype_, stride=num_prototype_).squeeze(0).squeeze(0)# (B, #class)\n",
        "\n",
        "      # first_dist_vec = torch.diag(first_dist_mat) #(B)\n",
        "      # second_dist_vec = torch.diag(second_dist_mat) # B\n",
        "      # confidence_mask = ((first_dist_vec- second_dist_vec) < 0).cuda()\n",
        "      \n",
        "      \n",
        "      # optimize target network using two types of pseudo labels\n",
        "      ce_from_s2t = nn.CrossEntropyLoss()(logit_t,pseudo_label)\n",
        "      # ce_from_s2t = forward(logit_t,pseudo_label_hot_s)\n",
        "      # ce_from_s2t = nn.CrossEntropyLoss(reduction = 'none')(logit_t, pseudo_label_s).view(-1,1).squeeze(1)\n",
        "      # ones = pseudo_label_s.sum(axis=0)\n",
        "      # zeros = 16-ones\n",
        "      # # # print(ce_from_s2t)\n",
        "      # # # print(ones)\n",
        "      # # # print(zeros)\n",
        "      # # # print(pseudo_label_s)\n",
        "      # # # print(1-pseudo_label_s)\n",
        "      # # # print(torch.mean(ce_from_s2t*pseudo_label_s,dim=0,keepdim=True)*(16/ones))\n",
        "      # # # print(torch.mean(ce_from_s2t*(1-pseudo_label_s),dim=0,keepdim=True)*(16/zeros))\n",
        "      # if ones!=0 and zeros!=0:\n",
        "      #   ce_from_s2t = (torch.mean(ce_from_s2t*pseudo_label_s,dim=0,keepdim=True)*(16/ones)+torch.mean(ce_from_s2t*(1-pseudo_label_s),dim=0,keepdim=True)*(16/zeros))/2\n",
        "      # else:\n",
        "      #   ce_from_s2t = torch.mean(ce_from_s2t, dim=0, keepdim=True)\n",
        "      # ce_from_s2t = nn.CrossEntropyLoss()(logit_t, pseudo_label_s)\n",
        "      \n",
        "      # ce_from_t = nn.CrossEntropyLoss(reduction='none')(logit_t, pseudo_label_t).view(-1, 1).squeeze(1)\n",
        "      # ce_from_t = torch.mean(ce_from_t*confidence_mask, dim=0, keepdim=True)*(16/confidence_mask.sum(axis=0))\n",
        "      \n",
        "      # alpha = np.float(2.0 / (1.0 + np.exp( -0.08* global_step / float(train_min_step//2))) - 1.0)   ### 0.8 for 0.8759 ## changed from -0.08 to -0.8\n",
        "      # alpha = 0\n",
        "      ce_total = ce_from_s2t\n",
        "      # ce_total = (1 - alpha)*ce_from_s2t + alpha*ce_from_t\n",
        "      if global_step%2==0:\n",
        "        batch_loss = ce_total\n",
        "      else:\n",
        "        batch_loss+=ce_total\n",
        "      global_step+=1 \n",
        "      if global_step%2==0:\n",
        "        # print(optimizer.param_groups[0]['lr'])\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss /= 2\n",
        "        batch_loss.backward(retain_graph=True)\n",
        "        # print(global_step,batch_loss)\n",
        "        optimizer.step()\n",
        "        lr_scheduler(optimizer, iter_num=global_step, max_iter=max_iter)\n",
        "      # optimizer.zero_grad()\n",
        "      # # # ce_from_s2t.backward(retain_graph=True)\n",
        "      # ce_total.backward(retain_graph=True)\n",
        "      # optimizer.step()\n",
        "      # print(global_step,ce_from_s2t.cpu().detach().numpy())\n",
        "      # print(global_step,alpha,ce_total.cpu().detach().numpy(),ce_from_s2t.cpu().detach().numpy(),ce_from_t.cpu().detach().numpy())\n",
        "      # global_step+=1\n",
        "\n",
        "\n",
        "    epoch_end_time=time.time()\n",
        "    print(\"time taken for epoch no. {} is {}\".format(epoch_id,epoch_end_time-epoch_start_time))\n",
        "    target_trainable_net.eval()\n",
        "    fixed_source_net.eval()\n",
        "    fscore,prec,recall = evaluation(test_dataloader,target_trainable_net,fixed_source_net)\n",
        "    l.append((fscore,prec,recall))\n",
        "    print(l)\n",
        "    # avg_acc[epoch_id]+=acc\n",
        "    # target_trainable_net.save_pretrained('drive/My Drive/models_without_APM/'+str(itr)+'_'+str(epoch_id)+'/')\n",
        "    # tokenizer1.save_pretrained('drive/My Drive/models_without_APM/'+str(itr)+'_'+str(epoch_id)+'/')\n",
        "    # if epoch_id == 3:\n",
        "    #   break\n",
        "    \n",
        "  #   if acc>best_acc:\n",
        "  #     best_acc=acc\n",
        "  #     best_epoch = epoch_id\n",
        "  #     target_trainable_net.save_pretrained(\"drive/My Drive/best_model2\")\n",
        "  #     tokenizer1.save_pretrained(\"drive/My Drive/best_model2\")\n",
        "    \n",
        "  print(cnt)\n",
        "  train_end_time = time.time()\n",
        "  print(\"Total_time taken : \",train_end_time-train_start_time)\n",
        "\n",
        "# print(avg_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time taken for epoch no. 1 is 488.34932136535645\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.884211     0.947692  0.8287\n",
            "[[4379   51]\n",
            " [ 191  924]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "[(0.8842105263157896, 0.9476923076923077, 0.8286995515695067)]\n",
            "time taken for epoch no. 2 is 487.50836515426636\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.882126     0.956021  0.818834\n",
            "[[4388   42]\n",
            " [ 202  913]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "[(0.8842105263157896, 0.9476923076923077, 0.8286995515695067), (0.8821256038647343, 0.956020942408377, 0.8188340807174888)]\n",
            "time taken for epoch no. 3 is 488.76512479782104\n",
            "model         f1 score    precision    recall\n",
            "----------  ----------  -----------  --------\n",
            "pretrained    0.834019     0.850746  0.817937\n",
            "trained       0.880153     0.945417  0.823318\n",
            "[[4377   53]\n",
            " [ 197  918]]\n",
            "[[4270  160]\n",
            " [ 203  912]]\n",
            "[(0.8842105263157896, 0.9476923076923077, 0.8286995515695067), (0.8821256038647343, 0.956020942408377, 0.8188340807174888), (0.8801534036433365, 0.945417095777549, 0.8233183856502242)]\n",
            "0\n",
            "Total_time taken :  1697.4774737358093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1li3RAdusCE",
        "outputId": "2396385b-7e87-46b6-ac6d-b9f27c1d983e"
      },
      "source": [
        "target_trainable_net.save_pretrained('drive/My Drive/proto_aug1')\n",
        "tokenizer1.save_pretrained('drive/My Drive/proto_aug1')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('drive/My Drive/proto_aug1/vocab.json',\n",
              " 'drive/My Drive/proto_aug1/merges.txt',\n",
              " 'drive/My Drive/proto_aug1/special_tokens_map.json',\n",
              " 'drive/My Drive/proto_aug1/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAiADYw1rFAV"
      },
      "source": [
        "# # lrs = [0.003,0.001,0.005,0.008]\n",
        "# # APM_update_freqs = [100,50,200]\n",
        "# # best_acc=0\n",
        "# # best_config = ()\n",
        "# # for lr in lrs:\n",
        "# #   for freq in APM_update_freqs:\n",
        "# #     acc,epoch = target_train(lr,freq)\n",
        "# #     print(lr,freq,epoch,acc)\n",
        "# #     if acc>best_acc:\n",
        "# #       best_acc=acc\n",
        "# #       best_config = (lr,freq,epoch)\n",
        "\n",
        "# # print(best_config,best_acc)\n",
        "\n",
        "# target_trainable_net.eval()\n",
        "# fixed_source_net.eval()\n",
        "# evaluation(test_dataloader,target_trainable_net,fixed_source_net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgU0Z9N7vmpC"
      },
      "source": [
        "# target_trainable_net.save_pretrained(\"drive/My Drive/best_model_without_APM_0.8624\")\n",
        "# tokenizer1.save_pretrained(\"drive/My Drive/best_model_without_APM_0.8624\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-kf68ew_X8O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}